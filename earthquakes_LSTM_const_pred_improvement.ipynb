{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import datetime as dt\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INFO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAVE_INFO == True):\n",
    "    DATA_DIR = 'Experiments/'\n",
    "    EXPERIMENT_DIR = DATA_DIR + 'LSTM_imrove_prediction_th=6/'\n",
    "    os.makedirs(EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посмотрим что мы имеем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета по дням и по клеткам в сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_BORDER = 0\n",
    "RIGHT_BORDER = 2000\n",
    "DOWN_BORDER = 0\n",
    "UP_BORDER = 2500\n",
    "\n",
    "N_CELLS_HOR = 200\n",
    "N_CELLS_VER = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9591, 1, 200, 250])\n"
     ]
    }
   ],
   "source": [
    "celled_data = torch.load(\"Data/celled_data_\"\n",
    "                         + str(N_CELLS_HOR)\n",
    "                         + \"x\"\n",
    "                         + str(N_CELLS_VER))\n",
    "print (celled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celled_data_RTL = torch.load(\"Data/RTL_features\")\n",
    "# print (celled_data_RTL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_day_image (tensor, day):\n",
    "    plt.imshow (tensor[day].squeeze(0), cmap=plt.cm.afmhot_r)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_one_day_quakes (tensor, day):\n",
    "    state = tensor[day].squeeze(0)\n",
    "    print (state.shape)\n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if (state[i][j] != 0):\n",
    "                X.append(i)\n",
    "                Y.append(j)\n",
    "                M.append(state[i][j].item())\n",
    "    print (X)\n",
    "    print (Y)\n",
    "    print (M)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    plt.axis([0, state.shape[0], 0, state.shape[1]])\n",
    "    axes.scatter(X, Y, s=500, c=M, marker='.', cmap=plt.cm.Reds)\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 250])\n",
      "[74, 88, 138, 149]\n",
      "[89, 87, 169, 177]\n",
      "[2.5, 2.5999999046325684, 3.700000047683716, 2.9000000953674316]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_one_day_quakes (celled_data, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "DEVICE_ID = 5\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "print (DEVICE)\n",
    "# torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy (input, target, threshold):\n",
    "    true = ((input>threshold) == target)\n",
    "    sum = torch.sum (true.float())\n",
    "    return sum/input.shape[0]/input.shape[1]/input.shape[2]/input.shape[3]\n",
    "\n",
    "def my_precision (input, target, threshold):\n",
    "    TP = torch.sum (((input>threshold) * target      ).float())\n",
    "    FP = torch.sum (((input>threshold) * (1 - target)).float())\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def my_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target).float())\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def my_precision_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold)  * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target      ).float())\n",
    "#     print ('TP = ', TP.item(), 'FP = ', FP.item(), 'FN = ', FN.item(), 'N = ', input.shape[0])\n",
    "    return TP / (TP + FP), TP / (TP + FN)\n",
    "\n",
    "def my_precision_TPR_FPR (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    TN = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return TP / (TP + FP), TP / (TP + FN), FP / (FP + TN)\n",
    "\n",
    "def my_TP_FN_FP_TN (input, target, threshold):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    matrix[0, 0] = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    matrix[1, 0] = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    matrix[0, 1] = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    matrix[1, 1] = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет\n",
    "#### (Может не влезть в оперативку (надо ~ 12Gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVED_DAYS = 64     # ~2 months\n",
    "DAYS_TO_PREDICT_AFTER  = 10\n",
    "DAYS_TO_PREDICT_BEFORE = 50\n",
    "TESTING_DAYS = 1000\n",
    "\n",
    "HEAVY_QUAKE_THRES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = (celled_data>HEAVY_QUAKE_THRES).float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 250])\n"
     ]
    }
   ],
   "source": [
    "print (mean_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeDataset_RNN_Usual_Train (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[0:\n",
    "                                (celled_data.shape[0] -\n",
    "                                 TESTING_DAYS)]\n",
    "        \n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        accurate_pred = ((torch.sum(self.data[(idx +\n",
    "                                              DAYS_TO_PREDICT_AFTER):\n",
    "                                             (idx +\n",
    "                                              DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                                   dim=0,\n",
    "                                   keepdim=True).squeeze(0) > 0).float()\n",
    "                         - mean_val)\n",
    "        return (self.data[(idx)],\n",
    "                torch.cat([1 - accurate_pred, accurate_pred], dim=0))\n",
    "        \n",
    "\n",
    "class EarthquakeDataset_RNN_Usual_Test (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[(celled_data.shape[0] -\n",
    "                                 TESTING_DAYS):\n",
    "                                (celled_data.shape[0])]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[(idx)],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EarthquakeDataset_RNN_Train (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[0:\n",
    "#                                 (celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS)]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[idx],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)\n",
    "        \n",
    "\n",
    "# class EarthquakeDataset_RNN_Test (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[(celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS):\n",
    "#                                 (celled_data.shape[0])]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[(idx)],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data : torch.Size([8591, 1, 200, 250])\n",
      "size      : 8541\n",
      "self.data : torch.Size([1000, 1, 200, 250])\n",
      "size      : 950\n"
     ]
    }
   ],
   "source": [
    "earthquakes_dataset_train = EarthquakeDataset_RNN_Usual_Train (celled_data)\n",
    "earthquakes_dataset_test  = EarthquakeDataset_RNN_Usual_Test  (celled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "\n",
    "earthquakes_dataloader_test  = DataLoader(earthquakes_dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим саму сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.CONV  = nn.Conv2d    (in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   bias=False)             # think about it later\n",
    "        \n",
    "        self.BNORM =nn.BatchNorm2d(out_channels,\n",
    "                                   eps=1e-05,\n",
    "                                   momentum=0.1,\n",
    "                                   affine=False)\n",
    "#         self.RELU  = nn.ReLU ()\n",
    "        \n",
    "#         self.MAXPOOL = nn.MaxPool2d(3,\n",
    "#                                     stride=1,\n",
    "#                                     padding=1,\n",
    "#                                     dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('sizeof(x) = ', x.size())\n",
    "        #print ('sizeof(xprev) = ', xprev.size())    \n",
    "        \n",
    "        x = self.CONV   (x)\n",
    "        x = self.BNORM  (x)\n",
    "#         x = self.RELU   (x)\n",
    "#         x = self.MAXPOOL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell (nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size=16, hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.  h_size = hidden_state_size\n",
    "        \n",
    "        self.embedding  = ConvBlock (1, embedding_size, 3)\n",
    "        self.RNN_update = nn.Sequential (ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size + embedding_size,\n",
    "                                                    kernel_size=3),\n",
    "                                         ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size,\n",
    "                                                    kernel_size=3))\n",
    "        self.RNN_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                       2, \n",
    "                                                       kernel_size=3),\n",
    "                                            nn.Softmax (dim=1))\n",
    "        \n",
    "    def forward (self, x, h_prev):\n",
    "        \n",
    "        x_emb   = self.embedding (x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
    "#         print (\"x_and_h : \", x_and_h.shape)\n",
    "        h_next  = self.RNN_update(x_and_h)\n",
    "#         print (\"h_prev :\", h_prev.shape)\n",
    "#         print (\"h_next :\", h_next.shape)\n",
    "        \n",
    "        assert h_prev.shape == h_next.shape\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        result = self.RNN_to_result(h_next)\n",
    "        return h_next, result\n",
    "    \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return torch.zeros(batch_size,\n",
    "                           self.h_size,\n",
    "                           N_CELLS_HOR, \n",
    "                           N_CELLS_VER,\n",
    "                           requires_grad=False,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "![LSTM](./img/LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell (nn.Module):\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  embedding_size=16,\n",
    "                  hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.hid_size = hidden_state_size\n",
    "        \n",
    "#         self.embedding = ConvBlock (1, self.emb_size, kernel_size=3)\n",
    "        self.embedding = nn.Sequential(ConvBlock(1,\n",
    "                                                 self.emb_size,\n",
    "                                                 3),\n",
    "                                       nn.ReLU(),\n",
    "                                       ConvBlock(self.emb_size,\n",
    "                                                 self.emb_size,\n",
    "                                                 3))\n",
    "        self.hidden_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                          2, \n",
    "                                                          kernel_size=3),\n",
    "                                               nn.Softmax (dim=1))\n",
    "        \n",
    "        self.f_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.i_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.c_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Tanh())\n",
    "        self.o_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        (prev_c, prev_h) = prev_state\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        x_and_h = torch.cat([prev_h, x_emb], dim=1)\n",
    "        \n",
    "        f_i = self.f_t(x_and_h)\n",
    "        i_i = self.i_t(x_and_h)\n",
    "        c_i = self.c_t(x_and_h)\n",
    "        o_i = self.o_t(x_and_h)\n",
    "        \n",
    "        next_c = prev_c * f_i + i_i * c_i\n",
    "        next_h = torch.tanh(next_c) * o_i\n",
    "        \n",
    "        assert prev_h.shape == next_h.shape\n",
    "        assert prev_c.shape == next_c.shape\n",
    "        \n",
    "        return (next_c, next_h), self.hidden_to_result(next_h)\n",
    "        \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)),\n",
    "                Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)))\n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция тренеровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossEntropy(weights, prediction, target):\n",
    "    assert len(weights) == prediction.shape[1]\n",
    "    assert prediction.shape == target.shape\n",
    "    loss = 0\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(len(weights)):\n",
    "            loss -= weights[j] * torch.sum(target[i, j] * prediction[i, j].log())\n",
    "    return loss / prediction.shape[2] / prediction.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN (RNN_cell,\n",
    "                       device,\n",
    "                       dataloader_train,\n",
    "                       n_cycles=1,\n",
    "                       learning_rate=0.0003,\n",
    "                       earthquake_weight=1.,\n",
    "                       lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for cycle in range(n_cycles):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "#         for data in tqdm(dataloader_train):\n",
    "        for data in dataloader_train:\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "#             print (\"inputs\", inputs.shape)\n",
    "#             print (\"hid_state\", hid_state.shape)\n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "            loss = my_crossEntropy(weights, outputs, labels)\n",
    "            loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "            if (type(hid_state) == tuple):\n",
    "                for elem in hid_state:\n",
    "                    elem.detach_()\n",
    "            else:\n",
    "                hid_state.detach_()\n",
    "            \n",
    "            if (i)%100==0:\n",
    "                clear_output(True)\n",
    "                print (\"Done :\", i, \"/\", dataloader_train.__len__())\n",
    "                plt.plot(loss_massive,label='loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            i += 1\n",
    "        learning_rate /= lr_decay\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CYCLES = 1\n",
    "LEARNING_RATE = 0.0003\n",
    "LR_DECAY = 10.\n",
    "EARTHQUAKE_WEIGHT = 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "HID_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done : 400 / 8541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-83d97836b3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mearthquake_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEARTHQUAKE_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                    \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR_DECAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                    )\n",
      "\u001b[0;32m<ipython-input-22-212b4d7684bc>\u001b[0m in \u001b[0;36mtrain_network_RNN\u001b[0;34m(RNN_cell, device, dataloader_train, n_cycles, learning_rate, earthquake_weight, lr_decay)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#             print (\"inputs\", inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#             print (\"hid_state\", hid_state.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mhid_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#             loss = criterion(outputs, labels.squeeze(1).long())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ceb0c23c4f32>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prev_state)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mprev_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx_and_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a9e6112862b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#print ('sizeof(xprev) = ', xprev.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONV\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBNORM\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         x = self.RELU   (x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RNN_cell = RNNCell()\n",
    "RNN_cell = LSTMCell(embedding_size    = EMB_SIZE,\n",
    "                    hidden_state_size = HID_SIZE)\n",
    "train_network_RNN (RNN_cell,\n",
    "                   DEVICE,\n",
    "                   earthquakes_dataloader_train,\n",
    "                   n_cycles=N_CYCLES,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                   lr_decay=LR_DECAY\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality (RNN_cell,\n",
    "                   device,\n",
    "                   dataloader_test,\n",
    "                   n_dots=501,\n",
    "                   info_file=None):\n",
    "    \n",
    "    prediction = torch.zeros(dataloader_test.__len__(),  N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    prediction.detach_()\n",
    "    target     = torch.zeros(dataloader_test.__len__(), N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    target.detach_()\n",
    "       \n",
    "    RNN_cell.to(device)\n",
    "\n",
    "    hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "    if (type(hid_state) == tuple):\n",
    "        for elem in hid_state:\n",
    "            elem.detach_()\n",
    "    else:\n",
    "        hid_state.detach_()\n",
    "        \n",
    "    i = 0\n",
    "    for data in tqdm(dataloader_test):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device).float()\n",
    "\n",
    "        hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "        \n",
    "        prediction[i] = outputs[:, 1, :, :]\n",
    "        target    [i] = labels.squeeze(0)\n",
    "    \n",
    "        if (type(hid_state) == tuple):\n",
    "            for elem in hid_state:\n",
    "                elem.detach_()\n",
    "        else:\n",
    "            hid_state.detach_()\n",
    "        prediction.detach_()\n",
    "        target    .detach_()\n",
    "        i += 1\n",
    "        \n",
    "    assert prediction.shape == target.shape\n",
    "    prediction = prediction [10:prediction.shape[0]]  # cutting peace of data because\n",
    "    prediction += mean_val.to(device)\n",
    "    target     = target     [10:target    .shape[0]]  # hidden state might be not good\n",
    "    \n",
    "    print (\"ROC_AUC_score = \", end='')\n",
    "    ROC_AUC_score = roc_auc_score(np.array(target    .view(-1).cpu()),\n",
    "                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (ROC_AUC_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('ROC_AUC               =', ROC_AUC_score, file=info_file)\n",
    "    \n",
    "    print (\"AVG_precision_score = \", end='')\n",
    "    AVG_precision_score = average_precision_score(np.array(target    .view(-1).cpu()),\n",
    "                                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (AVG_precision_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('Average_precision     =', AVG_precision_score, file=info_file)\n",
    "        \n",
    "    print ('\\n=======================')\n",
    "    \n",
    "    for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "        print ('Threshold = ', threshold)\n",
    "        print ('-----------------------')\n",
    "        print (my_TP_FN_FP_TN(prediction, target, threshold))\n",
    "        print ('=======================')\n",
    "    \n",
    "    if SAVE_INFO:\n",
    "        print ('\\n=======================', file=info_file)\n",
    "    \n",
    "        for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "            print ('Threshold = ', threshold                    , file=info_file)\n",
    "            print ('-----------------------'                    , file=info_file)\n",
    "            print (my_TP_FN_FP_TN(prediction, target, threshold), file=info_file)\n",
    "            print ('======================='                    , file=info_file)\n",
    "    \n",
    "    threshold_massive = torch.linspace (0, 1, n_dots, dtype=torch.float, device=device)\n",
    "    \n",
    "#     precision = np.zeros(n_dots)\n",
    "#     recall    = np.zeros(n_dots)\n",
    "#     FPR       = np.zeros(n_dots)\n",
    "\n",
    "    precision_massive = []\n",
    "    recall_massive    = []\n",
    "    FPR_massive       = []\n",
    "    \n",
    "    for threshold in tqdm(threshold_massive):\n",
    "        precision, recall, FPR = my_precision_TPR_FPR(prediction, target, threshold)\n",
    "        precision_massive.append(precision.item())\n",
    "        recall_massive   .append(recall.item())\n",
    "        FPR_massive      .append(FPR.item())\n",
    "    \n",
    "    # plot 1 precision\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), precision_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('precision')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2 recall\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), recall_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('recall')\n",
    "    \n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 3 ROC-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(FPR_massive, recall_massive, 'orange', marker = '^')\n",
    "    axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "    axes.set_xlabel('FPR')\n",
    "    axes.set_ylabel('TPR (recall)')\n",
    "    axes.set_title('ROC-curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 4 precision-recall-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(recall_massive, precision_massive, 'orange', marker = '^')\n",
    "\n",
    "    axes.set_xlabel('Recall')\n",
    "    axes.set_ylabel('Precision')\n",
    "    axes.set_title('Precision_Recall_curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_Recall_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    return ROC_AUC_score, AVG_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_INFO_to_file(info_file):\n",
    "        \n",
    "    print ('LEFT_BORDER           =', LEFT_BORDER                           , file=info_file)\n",
    "    print ('RIGHT_BORDER          =', RIGHT_BORDER                          , file=info_file)\n",
    "    print ('DOWN_BORDER           =', DOWN_BORDER                           , file=info_file)\n",
    "    print ('UP_BORDER             =', UP_BORDER                             , file=info_file)\n",
    "    print ('N_CELLS_HOR           =', N_CELLS_HOR                           , file=info_file)\n",
    "    print ('N_CELLS_VER           =', N_CELLS_VER                           , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('OBSERVED_DAYS         =', OBSERVED_DAYS                         , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_AFTER =', DAYS_TO_PREDICT_AFTER                 , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_BEFOR =', DAYS_TO_PREDICT_BEFORE                , file=info_file)\n",
    "    print ('TESTING_DAYS          =', TESTING_DAYS                          , file=info_file)\n",
    "    print ('HEAVY_QUAKE_THRES     =', HEAVY_QUAKE_THRES                     , file=info_file)\n",
    "    print ('LEARNING_RATE         =', LEARNING_RATE                         , file=info_file)\n",
    "    print ('LR_DECAY              =', LR_DECAY                              , file=info_file)\n",
    "    print ('N_CYCLES              =', N_CYCLES                              , file=info_file)\n",
    "    print ('EARTHQUAKE_WEIGHT     =', EARTHQUAKE_WEIGHT                     , file=info_file)\n",
    "    print ('TRAIN_SHAPE           =', earthquakes_dataset_train.data.shape  , file=info_file)\n",
    "    print ('TEST__SHAPE           =', earthquakes_dataset_test .data.shape  , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('EMB_SIZE              =', EMB_SIZE                              , file=info_file)\n",
    "    print ('HID_SIZE              =', HID_SIZE                              , file=info_file)\n",
    "    \n",
    "    \n",
    "#         print ('', , file=info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_cell.eval()\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file = open (EXPERIMENT_DIR + 'INFO.txt', 'w')\n",
    "else:\n",
    "    info_file = None\n",
    "\n",
    "if SAVE_INFO:\n",
    "    print_INFO_to_file(info_file)\n",
    "    \n",
    "ROC_AUC, AVG_prec = check_quality (RNN_cell,\n",
    "                                   DEVICE,\n",
    "                                   earthquakes_dataloader_test,\n",
    "                                   n_dots=251,\n",
    "                                   info_file=info_file)\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_CE (network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=200,\n",
    "#                       learning_rate=0.1,\n",
    "#                       earthquake_weight=1.):\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file = open (EXPERIMENT_DIR + 'Epochs_info.txt', 'w')\n",
    "    \n",
    "#     loss_acc  = []\n",
    "#     test_acc  = []\n",
    "#     test_prec = []\n",
    "#     test_rec  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     weights = torch.tensor([1., earthquake_weight], dtype = torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9)\n",
    "#             print ('Changed learning rate to ', learning_rate/10)\n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "#             print ('Changed learning rate to ', learning_rate/100)\n",
    "            \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.shape, outputs.dtype)\n",
    "# #             print ('labels  : ', labels.shape , labels.dtype)\n",
    "# #             outputs = torch.cat ((1-outputs, outputs), dim=1)\n",
    "# #             print ('outputs ', outputs.shape, '   [', outputs[1, 0, 12, 12], outputs[1, 1, 12, 12], ']')\n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         loss_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "# #         calculating test accuracy, precision and recall\n",
    "#         epoch_accuracy  = 0.0\n",
    "#         epoch_precision = 0.0\n",
    "#         epoch_recall    = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "# #             find_mistake(outputs)\n",
    "#             accuracy = my_accuracy (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "#             precision, recall = my_precision_recall (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "# #             accuracy2 = my_accuracy (outputs, labels, 1.0)\n",
    "            \n",
    "#             epoch_elems     += labels.shape[0]\n",
    "#             epoch_accuracy  += accuracy.item()  * labels.shape[0]\n",
    "#             epoch_precision += precision.item() * labels.shape[0]\n",
    "#             epoch_recall    += recall.item()    * labels.shape[0]\n",
    "\n",
    "# #         epoch_accuracy /= epoch_elems\n",
    "#         test_acc .append (epoch_accuracy  / epoch_elems)\n",
    "#         test_prec.append (epoch_precision / epoch_elems)\n",
    "#         test_rec .append (epoch_recall    / epoch_elems)\n",
    "        \n",
    "        \n",
    "#         print('Ep :', epoch,\n",
    "#               'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#               'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#               'prec_ts :' , round (test_prec[-1], 4),\n",
    "#               'rec_ts :'  , round (test_rec [-1], 4))\n",
    "        \n",
    "#         if (SAVE_INFO == True):\n",
    "#             print('Ep :', epoch,\n",
    "#                   'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#                   'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#                   'prec_ts :' , round (test_prec[-1], 4),\n",
    "#                   'rec_ts :'  , round (test_rec [-1], 4)\n",
    "#                   , file=epochs_file)\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "# #     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(loss_acc , label='Loss')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Loss_train.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_acc , label='Test Accuracy')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Accuracy_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_prec, label='Test Precision')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_rec , label='Test Recall')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEARNING_RATE = 0.1\n",
    "# N_EPOCHS = 200\n",
    "# EARTHQUAKE_WEIGHT = 10000.\n",
    "\n",
    "# earthquake_network = ConvNetwork_CE ()\n",
    "# train_network_CE  (earthquake_network,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=N_EPOCHS,\n",
    "#                    learning_rate=LEARNING_RATE,\n",
    "#                    earthquake_weight=EARTHQUAKE_WEIGHT\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_ROCinfo (model, dataLoader, device, alpha=0.5, n_dots=101):\n",
    "#     model = model.to(device)\n",
    "    \n",
    "    \n",
    "#     threshold_massive = np.linspace (0, n_dots-1, n_dots, dtype=int)\n",
    "#     TP_massive = np.zeros (n_dots)\n",
    "#     FP_massive = np.zeros (n_dots)\n",
    "#     FN_massive = np.zeros (n_dots)\n",
    "#     TN_massive = np.zeros (n_dots)\n",
    "    \n",
    "#     for data in dataLoader:\n",
    "#         inputs = data[0].to(device)\n",
    "#         labels = data[1].to(device)\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         for threshold in threshold_massive:\n",
    "#             prediction = (outputs[:, 1, :, :].unsqueeze(1))>(threshold/n_dots)\n",
    "#             TP_massive[threshold] += torch.sum (prediction       * labels      ).float()\n",
    "#             FP_massive[threshold] += torch.sum (prediction       * (1 - labels)).float()\n",
    "#             FN_massive[threshold] += torch.sum ((1 - prediction) * labels      ).float()\n",
    "#             TN_massive[threshold] += torch.sum ((1 - prediction) * (1 - labels)).float()\n",
    "            \n",
    "#     threshold_massive = threshold_massive / (n_dots-1)\n",
    "#     precision_massive = TP_massive / (TP_massive + FP_massive)\n",
    "#     TPR_massive       = TP_massive / (TP_massive + FN_massive)\n",
    "#     FPR_massive       = FP_massive / (FP_massive + TN_massive)\n",
    "\n",
    "#     sum_events = TP_massive[int(len(TP_massive)/2)] + FP_massive[int(len(FP_massive)/2)] + FN_massive[int(len(FN_massive)/2)] + TN_massive[int(len(TN_massive)/2)] \n",
    "#     print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "    \n",
    "#     # plot 1 precision\n",
    "#     fig1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig1.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, precision_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('precision')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 2 recall\n",
    "#     fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, TPR_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('recall')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 3 ROC-curve\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(FPR_massive, TPR_massive, 'orange', marker = '^')\n",
    "#     axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "#     axes.set_xlabel('FPR')\n",
    "#     axes.set_ylabel('TPR (recall)')\n",
    "#     axes.set_title('ROC-curve')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     del model\n",
    "#     del inputs\n",
    "#     del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNetwork_MSE (nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(ConvNetwork_CE, self).__init__()\n",
    "        \n",
    "#         self.features = nn.Sequential()\n",
    "        \n",
    "#         self.features.add_module('conv1', conv_block(     OBSERVED_DAYS    , int (OBSERVED_DAYS/2 ), 3))\n",
    "#         self.features.add_module('conv2', conv_block(int (OBSERVED_DAYS/2 ), int (OBSERVED_DAYS/4 ), 3))\n",
    "#         self.features.add_module('conv3', conv_block(int (OBSERVED_DAYS/4 ), int (OBSERVED_DAYS/8 ), 3))\n",
    "#         self.features.add_module('conv4', conv_block(int (OBSERVED_DAYS/8 ), int (OBSERVED_DAYS/16), 3))\n",
    "#         self.features.add_module('conv5', conv_block(int (OBSERVED_DAYS/16),                      1, 3))\n",
    "        \n",
    "#         # might be a good idea to add an extra full connected layer\n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         print ('input  : ', x.shape)\n",
    "#         x = self.features(x)\n",
    "# #         print ('output : ', x.shape)\n",
    "#         return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_MSE(network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=164,\n",
    "#                       learning_rate=0.1):\n",
    "    \n",
    "#     train_acc = []\n",
    "#     test_acc  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    \n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9) \n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.dtype)\n",
    "# #             print ('labels  : ', labels.dtype)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         # calculating test accuracy\n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         test_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         print('Epoch : ', epoch, 'acc_train : ', round (train_acc[-1], 4), 'acc_test : ', round (test_acc[-1], 4))\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "#     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(test_acc , label='Test' )\n",
    "#     plt.legend()\n",
    "#     plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthquake_netowrk = ConvNetwork_MSE ()\n",
    "# train_network_MSE (earthquake_netowrk,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=200,\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_mistake (x):\n",
    "#     assert (torch.sum((x < 0.0) + (x > 1.0)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print ('input  : ', input.shape, input.dtype)\n",
    "# print (input)\n",
    "# print (torch.sum (input, dim = 0))\n",
    "# print ('target : ', target.shape, target.dtype)\n",
    "# print (target)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class someDataset (Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.data = torch.ones ([100, 32, 10, 10])\n",
    "#         self.labels = torch.ones ([100, 1, 10, 10])\n",
    "#         self.len  = self.data.shape[0]\n",
    "        \n",
    "#         print (self.data.shape)\n",
    "#         print (self.labels.shape)\n",
    "        \n",
    "#     def __len__ (self):\n",
    "#         return self.len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         print ('data_shape = ', self.data[idx].shape)\n",
    "#         print ('result_shape = ', self.labels[idx].shape)\n",
    "#         return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_dataset = someDataset()\n",
    "# dataloader = DataLoader (some_dataset,\n",
    "#                          batch_size=32,\n",
    "#                          shuffle=True,\n",
    "#                          num_workers=1,\n",
    "#                          )\n",
    "\n",
    "# for i, batch in enumerate(dataloader, 0):\n",
    "#     data = batch[0]\n",
    "#     print (i, 'data ', data.shape)\n",
    "#     labels = batch[1]\n",
    "#     print (i, 'labels ', labels.shape)\n",
    "    \n",
    "\n",
    "\n",
    "# # eartquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "# #                                          batch_size=33,\n",
    "# #                                          shuffle=True,\n",
    "# #                                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
