{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import datetime as dt\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INFO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAVE_INFO == True):\n",
    "    DATA_DIR = 'Experiments/'\n",
    "    EXPERIMENT_DIR = DATA_DIR + 'LSTM_imrove_prediction_th=6/'\n",
    "    os.makedirs(EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посмотрим что мы имеем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета по дням и по клеткам в сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_BORDER = 0\n",
    "RIGHT_BORDER = 2000\n",
    "DOWN_BORDER = 0\n",
    "UP_BORDER = 2500\n",
    "\n",
    "N_CELLS_HOR = 160\n",
    "N_CELLS_VER = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9591, 1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "celled_data = torch.load(\"Data/celled_data_\"\n",
    "                         + str(N_CELLS_HOR)\n",
    "                         + \"x\"\n",
    "                         + str(N_CELLS_VER))\n",
    "print (celled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celled_data_RTL = torch.load(\"Data/RTL_features\")\n",
    "# print (celled_data_RTL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_day_image (tensor, day):\n",
    "    plt.imshow (tensor[day].squeeze(0), cmap=plt.cm.afmhot_r)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_one_day_quakes (tensor, day):\n",
    "    state = tensor[day].squeeze(0)\n",
    "    print (state.shape)\n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if (state[i][j] != 0):\n",
    "                X.append(i)\n",
    "                Y.append(j)\n",
    "                M.append(state[i][j].item())\n",
    "    print (X)\n",
    "    print (Y)\n",
    "    print (M)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    plt.axis([0, state.shape[0], 0, state.shape[1]])\n",
    "    axes.scatter(X, Y, s=500, c=M, marker='.', cmap=plt.cm.Reds)\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 200])\n",
      "[59, 70, 111, 119]\n",
      "[71, 69, 135, 142]\n",
      "[2.5, 2.5999999046325684, 3.700000047683716, 2.9000000953674316]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_one_day_quakes (celled_data, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "DEVICE_ID = 5\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "print (DEVICE)\n",
    "# torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy (input, target, threshold):\n",
    "    true = ((input>threshold) == target)\n",
    "    sum = torch.sum (true.float())\n",
    "    return sum/input.shape[0]/input.shape[1]/input.shape[2]/input.shape[3]\n",
    "\n",
    "def my_precision (input, target, threshold):\n",
    "    TP = torch.sum (((input>threshold) * target      ).float())\n",
    "    FP = torch.sum (((input>threshold) * (1 - target)).float())\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def my_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target).float())\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def my_precision_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold)  * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target      ).float())\n",
    "#     print ('TP = ', TP.item(), 'FP = ', FP.item(), 'FN = ', FN.item(), 'N = ', input.shape[0])\n",
    "    return TP / (TP + FP), TP / (TP + FN)\n",
    "\n",
    "def my_precision_TPR_FPR (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    TN = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return TP / (TP + FP), TP / (TP + FN), FP / (FP + TN)\n",
    "\n",
    "def my_TP_FN_FP_TN (input, target, threshold):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    matrix[0, 0] = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    matrix[1, 0] = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    matrix[0, 1] = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    matrix[1, 1] = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет\n",
    "#### (Может не влезть в оперативку (надо ~ 12Gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVED_DAYS = 64     # ~2 months\n",
    "DAYS_TO_PREDICT_AFTER  = 10\n",
    "DAYS_TO_PREDICT_BEFORE = 50\n",
    "TESTING_DAYS = 1000\n",
    "\n",
    "HEAVY_QUAKE_THRES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = (celled_data[0:(celled_data.shape[0] - TESTING_DAYS)]>HEAVY_QUAKE_THRES).float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "print (mean_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeDataset_RNN_Usual_Train (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[0:\n",
    "                                (celled_data.shape[0] -\n",
    "                                 TESTING_DAYS)]\n",
    "        \n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        accurate_pred = ((torch.sum(self.data[(idx +\n",
    "                                              DAYS_TO_PREDICT_AFTER):\n",
    "                                             (idx +\n",
    "                                              DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                                   dim=0,\n",
    "                                   keepdim=True).squeeze(0) > 0).float()\n",
    "                         - mean_val)\n",
    "        return (self.data[(idx)],\n",
    "                torch.cat([1 - accurate_pred, accurate_pred], dim=0))\n",
    "        \n",
    "\n",
    "class EarthquakeDataset_RNN_Usual_Test (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[(celled_data.shape[0] -\n",
    "                                 TESTING_DAYS):\n",
    "                                (celled_data.shape[0])]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[(idx)],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EarthquakeDataset_RNN_Train (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[0:\n",
    "#                                 (celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS)]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[idx],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)\n",
    "        \n",
    "\n",
    "# class EarthquakeDataset_RNN_Test (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[(celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS):\n",
    "#                                 (celled_data.shape[0])]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[(idx)],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data : torch.Size([8591, 1, 160, 200])\n",
      "size      : 8541\n",
      "self.data : torch.Size([1000, 1, 160, 200])\n",
      "size      : 950\n"
     ]
    }
   ],
   "source": [
    "earthquakes_dataset_train = EarthquakeDataset_RNN_Usual_Train (celled_data)\n",
    "earthquakes_dataset_test  = EarthquakeDataset_RNN_Usual_Test  (celled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "\n",
    "earthquakes_dataloader_test  = DataLoader(earthquakes_dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим саму сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.CONV  = nn.Conv2d    (in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   bias=False)             # think about it later\n",
    "        \n",
    "        self.BNORM =nn.BatchNorm2d(out_channels,\n",
    "                                   eps=1e-05,\n",
    "                                   momentum=0.1,\n",
    "                                   affine=False)\n",
    "#         self.RELU  = nn.ReLU ()\n",
    "        \n",
    "#         self.MAXPOOL = nn.MaxPool2d(3,\n",
    "#                                     stride=1,\n",
    "#                                     padding=1,\n",
    "#                                     dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('sizeof(x) = ', x.size())\n",
    "        #print ('sizeof(xprev) = ', xprev.size())    \n",
    "        \n",
    "        x = self.CONV   (x)\n",
    "        x = self.BNORM  (x)\n",
    "#         x = self.RELU   (x)\n",
    "#         x = self.MAXPOOL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell (nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size=16, hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.  h_size = hidden_state_size\n",
    "        \n",
    "        self.embedding  = ConvBlock (1, embedding_size, 3)\n",
    "        self.RNN_update = nn.Sequential (ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size + embedding_size,\n",
    "                                                    kernel_size=3),\n",
    "                                         ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size,\n",
    "                                                    kernel_size=3))\n",
    "        self.RNN_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                       2, \n",
    "                                                       kernel_size=3),\n",
    "                                            nn.Softmax (dim=1))\n",
    "        \n",
    "    def forward (self, x, h_prev):\n",
    "        \n",
    "        x_emb   = self.embedding (x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
    "#         print (\"x_and_h : \", x_and_h.shape)\n",
    "        h_next  = self.RNN_update(x_and_h)\n",
    "#         print (\"h_prev :\", h_prev.shape)\n",
    "#         print (\"h_next :\", h_next.shape)\n",
    "        \n",
    "        assert h_prev.shape == h_next.shape\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        result = self.RNN_to_result(h_next)\n",
    "        return h_next, result\n",
    "    \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return torch.zeros(batch_size,\n",
    "                           self.h_size,\n",
    "                           N_CELLS_HOR, \n",
    "                           N_CELLS_VER,\n",
    "                           requires_grad=False,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "![LSTM](./img/LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell (nn.Module):\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  embedding_size=16,\n",
    "                  hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.hid_size = hidden_state_size\n",
    "        \n",
    "#         self.embedding = ConvBlock (1, self.emb_size, kernel_size=3)\n",
    "        self.embedding = nn.Sequential(ConvBlock(1,\n",
    "                                                 self.emb_size,\n",
    "                                                 3),\n",
    "                                       nn.ReLU(),\n",
    "                                       ConvBlock(self.emb_size,\n",
    "                                                 self.emb_size,\n",
    "                                                 3))\n",
    "        self.hidden_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                          2, \n",
    "                                                          kernel_size=3),\n",
    "                                               nn.Softmax (dim=1))\n",
    "        \n",
    "        self.f_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.i_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.c_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Tanh())\n",
    "        self.o_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        (prev_c, prev_h) = prev_state\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        x_and_h = torch.cat([prev_h, x_emb], dim=1)\n",
    "        \n",
    "        f_i = self.f_t(x_and_h)\n",
    "        i_i = self.i_t(x_and_h)\n",
    "        c_i = self.c_t(x_and_h)\n",
    "        o_i = self.o_t(x_and_h)\n",
    "        \n",
    "        next_c = prev_c * f_i + i_i * c_i\n",
    "        next_h = torch.tanh(next_c) * o_i\n",
    "        \n",
    "        assert prev_h.shape == next_h.shape\n",
    "        assert prev_c.shape == next_c.shape\n",
    "        \n",
    "        return (next_c, next_h), self.hidden_to_result(next_h)\n",
    "        \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)),\n",
    "                Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)))\n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeConstRNN (nn.Module):\n",
    "    def __init__ (self,\n",
    "                  mean_val):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.mean_val = torch.cat((1 - mean_val, mean_val), dim=0)\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        return prev_state, torch.cat([self.mean_val.unsqueeze(0) for i in range(x.shape[0])], dim=0)\n",
    "    \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (torch.zeros((1)), torch.zeros((1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция тренеровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossEntropy(weights, prediction, target):\n",
    "    assert len(weights) == prediction.shape[1]\n",
    "    assert prediction.shape == target.shape\n",
    "    loss = 0\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(len(weights)):\n",
    "            loss -= weights[j] * torch.sum(target[i, j] * prediction[i, j].log())\n",
    "    return loss / prediction.shape[2] / prediction.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN (RNN_cell,\n",
    "                       device,\n",
    "                       dataloader_train,\n",
    "                       n_cycles=1,\n",
    "                       learning_rate=0.0003,\n",
    "                       earthquake_weight=1.,\n",
    "                       lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for cycle in range(n_cycles):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "#         for data in tqdm(dataloader_train):\n",
    "        for data in dataloader_train:\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "#             print (\"inputs\", inputs.shape)\n",
    "#             print (\"hid_state\", hid_state.shape)\n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "            loss = my_crossEntropy(weights, outputs, labels)\n",
    "            loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "            if (type(hid_state) == tuple):\n",
    "                for elem in hid_state:\n",
    "                    elem.detach_()\n",
    "            else:\n",
    "                hid_state.detach_()\n",
    "            \n",
    "            if (i)%100==0:\n",
    "                clear_output(True)\n",
    "                print (\"Done :\", i, \"/\", dataloader_train.__len__())\n",
    "                plt.plot(loss_massive,label='loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            i += 1\n",
    "        learning_rate /= lr_decay\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CYCLES = 1\n",
    "LEARNING_RATE = 0.0003\n",
    "LR_DECAY = 10.\n",
    "EARTHQUAKE_WEIGHT = 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "HID_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN_cell = RNNCell()\n",
    "# RNN_cell = LSTMCell(embedding_size    = EMB_SIZE,\n",
    "#                     hidden_state_size = HID_SIZE)\n",
    "RNN_cell = FakeConstRNN(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network_RNN (RNN_cell,\n",
    "                   DEVICE,\n",
    "                   earthquakes_dataloader_train,\n",
    "                   n_cycles=N_CYCLES,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                   lr_decay=LR_DECAY\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality (RNN_cell,\n",
    "                   device,\n",
    "                   dataloader_test,\n",
    "                   n_dots=501,\n",
    "                   info_file=None):\n",
    "    \n",
    "    prediction = torch.zeros(dataloader_test.__len__(),  N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    prediction.detach_()\n",
    "    target     = torch.zeros(dataloader_test.__len__(), N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    target.detach_()\n",
    "       \n",
    "    RNN_cell.to(device)\n",
    "\n",
    "    hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "    if (type(hid_state) == tuple):\n",
    "        for elem in hid_state:\n",
    "            elem.detach_()\n",
    "    else:\n",
    "        hid_state.detach_()\n",
    "        \n",
    "    i = 0\n",
    "    for data in tqdm(dataloader_test):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device).float()\n",
    "\n",
    "        hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "        \n",
    "        prediction[i] = outputs[:, 1, :, :]\n",
    "        target    [i] = labels.squeeze(0)\n",
    "    \n",
    "        if (type(hid_state) == tuple):\n",
    "            for elem in hid_state:\n",
    "                elem.detach_()\n",
    "        else:\n",
    "            hid_state.detach_()\n",
    "        prediction.detach_()\n",
    "        target    .detach_()\n",
    "        i += 1\n",
    "        \n",
    "    assert prediction.shape == target.shape\n",
    "    prediction = prediction [10:prediction.shape[0]]  # cutting peace of data because\n",
    "    prediction += mean_val.to(device)\n",
    "    target     = target     [10:target    .shape[0]]  # hidden state might be not good\n",
    "    \n",
    "    print (\"ROC_AUC_score = \", end='')\n",
    "    ROC_AUC_score = roc_auc_score(np.array(target    .view(-1).cpu()),\n",
    "                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (ROC_AUC_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('ROC_AUC               =', ROC_AUC_score, file=info_file)\n",
    "    \n",
    "    print (\"AVG_precision_score = \", end='')\n",
    "    AVG_precision_score = average_precision_score(np.array(target    .view(-1).cpu()),\n",
    "                                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (AVG_precision_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('Average_precision     =', AVG_precision_score, file=info_file)\n",
    "        \n",
    "    print ('\\n=======================')\n",
    "    \n",
    "    for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "        print ('Threshold = ', threshold)\n",
    "        print ('-----------------------')\n",
    "        print (my_TP_FN_FP_TN(prediction, target, threshold))\n",
    "        print ('=======================')\n",
    "    \n",
    "    if SAVE_INFO:\n",
    "        print ('\\n=======================', file=info_file)\n",
    "    \n",
    "        for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "            print ('Threshold = ', threshold                    , file=info_file)\n",
    "            print ('-----------------------'                    , file=info_file)\n",
    "            print (my_TP_FN_FP_TN(prediction, target, threshold), file=info_file)\n",
    "            print ('======================='                    , file=info_file)\n",
    "    \n",
    "    threshold_massive = torch.linspace (0, 1, n_dots, dtype=torch.float, device=device)\n",
    "    \n",
    "#     precision = np.zeros(n_dots)\n",
    "#     recall    = np.zeros(n_dots)\n",
    "#     FPR       = np.zeros(n_dots)\n",
    "\n",
    "    precision_massive = []\n",
    "    recall_massive    = []\n",
    "    FPR_massive       = []\n",
    "    \n",
    "    for threshold in tqdm(threshold_massive):\n",
    "        precision, recall, FPR = my_precision_TPR_FPR(prediction, target, threshold)\n",
    "        precision_massive.append(precision.item())\n",
    "        recall_massive   .append(recall.item())\n",
    "        FPR_massive      .append(FPR.item())\n",
    "    \n",
    "    # plot 1 precision\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), precision_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('precision')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2 recall\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), recall_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('recall')\n",
    "    \n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 3 ROC-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(FPR_massive, recall_massive, 'orange', marker = '^')\n",
    "    axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "    axes.set_xlabel('FPR')\n",
    "    axes.set_ylabel('TPR (recall)')\n",
    "    axes.set_title('ROC-curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 4 precision-recall-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(recall_massive, precision_massive, 'orange', marker = '^')\n",
    "\n",
    "    axes.set_xlabel('Recall')\n",
    "    axes.set_ylabel('Precision')\n",
    "    axes.set_title('Precision_Recall_curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_Recall_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    return ROC_AUC_score, AVG_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_INFO_to_file(info_file):\n",
    "        \n",
    "    print ('LEFT_BORDER           =', LEFT_BORDER                           , file=info_file)\n",
    "    print ('RIGHT_BORDER          =', RIGHT_BORDER                          , file=info_file)\n",
    "    print ('DOWN_BORDER           =', DOWN_BORDER                           , file=info_file)\n",
    "    print ('UP_BORDER             =', UP_BORDER                             , file=info_file)\n",
    "    print ('N_CELLS_HOR           =', N_CELLS_HOR                           , file=info_file)\n",
    "    print ('N_CELLS_VER           =', N_CELLS_VER                           , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('OBSERVED_DAYS         =', OBSERVED_DAYS                         , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_AFTER =', DAYS_TO_PREDICT_AFTER                 , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_BEFOR =', DAYS_TO_PREDICT_BEFORE                , file=info_file)\n",
    "    print ('TESTING_DAYS          =', TESTING_DAYS                          , file=info_file)\n",
    "    print ('HEAVY_QUAKE_THRES     =', HEAVY_QUAKE_THRES                     , file=info_file)\n",
    "    print ('LEARNING_RATE         =', LEARNING_RATE                         , file=info_file)\n",
    "    print ('LR_DECAY              =', LR_DECAY                              , file=info_file)\n",
    "    print ('N_CYCLES              =', N_CYCLES                              , file=info_file)\n",
    "    print ('EARTHQUAKE_WEIGHT     =', EARTHQUAKE_WEIGHT                     , file=info_file)\n",
    "    print ('TRAIN_SHAPE           =', earthquakes_dataset_train.data.shape  , file=info_file)\n",
    "    print ('TEST__SHAPE           =', earthquakes_dataset_test .data.shape  , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('EMB_SIZE              =', EMB_SIZE                              , file=info_file)\n",
    "    print ('HID_SIZE              =', HID_SIZE                              , file=info_file)\n",
    "    \n",
    "    \n",
    "#         print ('', , file=info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5661c12ea8a74b3c8273455385a02428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=950), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC_AUC_score = 0.7152143145784122\n",
      "AVG_precision_score = 0.0028963554965773684\n",
      "\n",
      "=======================\n",
      "Threshold =  0.2\n",
      "-----------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7c598ad1fa3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                    \u001b[0mearthquakes_dataloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                    \u001b[0mn_dots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m251\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                    info_file=info_file)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSAVE_INFO\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-d94c80cf4e0b>\u001b[0m in \u001b[0;36mcheck_quality\u001b[0;34m(RNN_cell, device, dataloader_test, n_dots, info_file)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Threshold = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmy_TP_FN_FP_TN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'======================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6a63b0d93d42>\u001b[0m in \u001b[0;36mmy_TP_FN_FP_TN\u001b[0;34m(input, target, threshold)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m      \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m      \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
     ]
    }
   ],
   "source": [
    "RNN_cell.eval()\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file = open (EXPERIMENT_DIR + 'INFO.txt', 'w')\n",
    "else:\n",
    "    info_file = None\n",
    "\n",
    "if SAVE_INFO:\n",
    "    print_INFO_to_file(info_file)\n",
    "    \n",
    "ROC_AUC, AVG_prec = check_quality (RNN_cell,\n",
    "                                   DEVICE,\n",
    "                                   earthquakes_dataloader_test,\n",
    "                                   n_dots=251,\n",
    "                                   info_file=info_file)\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_CE (network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=200,\n",
    "#                       learning_rate=0.1,\n",
    "#                       earthquake_weight=1.):\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file = open (EXPERIMENT_DIR + 'Epochs_info.txt', 'w')\n",
    "    \n",
    "#     loss_acc  = []\n",
    "#     test_acc  = []\n",
    "#     test_prec = []\n",
    "#     test_rec  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     weights = torch.tensor([1., earthquake_weight], dtype = torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9)\n",
    "#             print ('Changed learning rate to ', learning_rate/10)\n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "#             print ('Changed learning rate to ', learning_rate/100)\n",
    "            \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.shape, outputs.dtype)\n",
    "# #             print ('labels  : ', labels.shape , labels.dtype)\n",
    "# #             outputs = torch.cat ((1-outputs, outputs), dim=1)\n",
    "# #             print ('outputs ', outputs.shape, '   [', outputs[1, 0, 12, 12], outputs[1, 1, 12, 12], ']')\n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         loss_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "# #         calculating test accuracy, precision and recall\n",
    "#         epoch_accuracy  = 0.0\n",
    "#         epoch_precision = 0.0\n",
    "#         epoch_recall    = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "# #             find_mistake(outputs)\n",
    "#             accuracy = my_accuracy (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "#             precision, recall = my_precision_recall (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "# #             accuracy2 = my_accuracy (outputs, labels, 1.0)\n",
    "            \n",
    "#             epoch_elems     += labels.shape[0]\n",
    "#             epoch_accuracy  += accuracy.item()  * labels.shape[0]\n",
    "#             epoch_precision += precision.item() * labels.shape[0]\n",
    "#             epoch_recall    += recall.item()    * labels.shape[0]\n",
    "\n",
    "# #         epoch_accuracy /= epoch_elems\n",
    "#         test_acc .append (epoch_accuracy  / epoch_elems)\n",
    "#         test_prec.append (epoch_precision / epoch_elems)\n",
    "#         test_rec .append (epoch_recall    / epoch_elems)\n",
    "        \n",
    "        \n",
    "#         print('Ep :', epoch,\n",
    "#               'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#               'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#               'prec_ts :' , round (test_prec[-1], 4),\n",
    "#               'rec_ts :'  , round (test_rec [-1], 4))\n",
    "        \n",
    "#         if (SAVE_INFO == True):\n",
    "#             print('Ep :', epoch,\n",
    "#                   'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#                   'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#                   'prec_ts :' , round (test_prec[-1], 4),\n",
    "#                   'rec_ts :'  , round (test_rec [-1], 4)\n",
    "#                   , file=epochs_file)\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "# #     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(loss_acc , label='Loss')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Loss_train.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_acc , label='Test Accuracy')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Accuracy_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_prec, label='Test Precision')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_rec , label='Test Recall')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEARNING_RATE = 0.1\n",
    "# N_EPOCHS = 200\n",
    "# EARTHQUAKE_WEIGHT = 10000.\n",
    "\n",
    "# earthquake_network = ConvNetwork_CE ()\n",
    "# train_network_CE  (earthquake_network,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=N_EPOCHS,\n",
    "#                    learning_rate=LEARNING_RATE,\n",
    "#                    earthquake_weight=EARTHQUAKE_WEIGHT\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_ROCinfo (model, dataLoader, device, alpha=0.5, n_dots=101):\n",
    "#     model = model.to(device)\n",
    "    \n",
    "    \n",
    "#     threshold_massive = np.linspace (0, n_dots-1, n_dots, dtype=int)\n",
    "#     TP_massive = np.zeros (n_dots)\n",
    "#     FP_massive = np.zeros (n_dots)\n",
    "#     FN_massive = np.zeros (n_dots)\n",
    "#     TN_massive = np.zeros (n_dots)\n",
    "    \n",
    "#     for data in dataLoader:\n",
    "#         inputs = data[0].to(device)\n",
    "#         labels = data[1].to(device)\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         for threshold in threshold_massive:\n",
    "#             prediction = (outputs[:, 1, :, :].unsqueeze(1))>(threshold/n_dots)\n",
    "#             TP_massive[threshold] += torch.sum (prediction       * labels      ).float()\n",
    "#             FP_massive[threshold] += torch.sum (prediction       * (1 - labels)).float()\n",
    "#             FN_massive[threshold] += torch.sum ((1 - prediction) * labels      ).float()\n",
    "#             TN_massive[threshold] += torch.sum ((1 - prediction) * (1 - labels)).float()\n",
    "            \n",
    "#     threshold_massive = threshold_massive / (n_dots-1)\n",
    "#     precision_massive = TP_massive / (TP_massive + FP_massive)\n",
    "#     TPR_massive       = TP_massive / (TP_massive + FN_massive)\n",
    "#     FPR_massive       = FP_massive / (FP_massive + TN_massive)\n",
    "\n",
    "#     sum_events = TP_massive[int(len(TP_massive)/2)] + FP_massive[int(len(FP_massive)/2)] + FN_massive[int(len(FN_massive)/2)] + TN_massive[int(len(TN_massive)/2)] \n",
    "#     print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "    \n",
    "#     # plot 1 precision\n",
    "#     fig1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig1.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, precision_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('precision')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 2 recall\n",
    "#     fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, TPR_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('recall')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 3 ROC-curve\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(FPR_massive, TPR_massive, 'orange', marker = '^')\n",
    "#     axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "#     axes.set_xlabel('FPR')\n",
    "#     axes.set_ylabel('TPR (recall)')\n",
    "#     axes.set_title('ROC-curve')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     del model\n",
    "#     del inputs\n",
    "#     del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNetwork_MSE (nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(ConvNetwork_CE, self).__init__()\n",
    "        \n",
    "#         self.features = nn.Sequential()\n",
    "        \n",
    "#         self.features.add_module('conv1', conv_block(     OBSERVED_DAYS    , int (OBSERVED_DAYS/2 ), 3))\n",
    "#         self.features.add_module('conv2', conv_block(int (OBSERVED_DAYS/2 ), int (OBSERVED_DAYS/4 ), 3))\n",
    "#         self.features.add_module('conv3', conv_block(int (OBSERVED_DAYS/4 ), int (OBSERVED_DAYS/8 ), 3))\n",
    "#         self.features.add_module('conv4', conv_block(int (OBSERVED_DAYS/8 ), int (OBSERVED_DAYS/16), 3))\n",
    "#         self.features.add_module('conv5', conv_block(int (OBSERVED_DAYS/16),                      1, 3))\n",
    "        \n",
    "#         # might be a good idea to add an extra full connected layer\n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         print ('input  : ', x.shape)\n",
    "#         x = self.features(x)\n",
    "# #         print ('output : ', x.shape)\n",
    "#         return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_MSE(network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=164,\n",
    "#                       learning_rate=0.1):\n",
    "    \n",
    "#     train_acc = []\n",
    "#     test_acc  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    \n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9) \n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.dtype)\n",
    "# #             print ('labels  : ', labels.dtype)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         # calculating test accuracy\n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         test_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         print('Epoch : ', epoch, 'acc_train : ', round (train_acc[-1], 4), 'acc_test : ', round (test_acc[-1], 4))\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "#     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(test_acc , label='Test' )\n",
    "#     plt.legend()\n",
    "#     plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthquake_netowrk = ConvNetwork_MSE ()\n",
    "# train_network_MSE (earthquake_netowrk,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=200,\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_mistake (x):\n",
    "#     assert (torch.sum((x < 0.0) + (x > 1.0)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print ('input  : ', input.shape, input.dtype)\n",
    "# print (input)\n",
    "# print (torch.sum (input, dim = 0))\n",
    "# print ('target : ', target.shape, target.dtype)\n",
    "# print (target)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class someDataset (Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.data = torch.ones ([100, 32, 10, 10])\n",
    "#         self.labels = torch.ones ([100, 1, 10, 10])\n",
    "#         self.len  = self.data.shape[0]\n",
    "        \n",
    "#         print (self.data.shape)\n",
    "#         print (self.labels.shape)\n",
    "        \n",
    "#     def __len__ (self):\n",
    "#         return self.len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         print ('data_shape = ', self.data[idx].shape)\n",
    "#         print ('result_shape = ', self.labels[idx].shape)\n",
    "#         return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_dataset = someDataset()\n",
    "# dataloader = DataLoader (some_dataset,\n",
    "#                          batch_size=32,\n",
    "#                          shuffle=True,\n",
    "#                          num_workers=1,\n",
    "#                          )\n",
    "\n",
    "# for i, batch in enumerate(dataloader, 0):\n",
    "#     data = batch[0]\n",
    "#     print (i, 'data ', data.shape)\n",
    "#     labels = batch[1]\n",
    "#     print (i, 'labels ', labels.shape)\n",
    "    \n",
    "\n",
    "\n",
    "# # eartquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "# #                                          batch_size=33,\n",
    "# #                                          shuffle=True,\n",
    "# #                                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
