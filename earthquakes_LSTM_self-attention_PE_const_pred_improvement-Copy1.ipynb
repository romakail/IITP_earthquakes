{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import datetime as dt\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INFO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAVE_INFO == True):\n",
    "    DATA_DIR = 'Experiments/'\n",
    "    EXPERIMENT_DIR = DATA_DIR + 'Self_attention_no_PE_0/'\n",
    "    os.makedirs(EXPERIMENT_DIR)\n",
    "    \n",
    "READY_DIR = 'ready/no_PE/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посмотрим что мы имеем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета по дням и по клеткам в сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_BORDER = 0\n",
    "RIGHT_BORDER = 2000\n",
    "DOWN_BORDER = 0\n",
    "UP_BORDER = 2500\n",
    "\n",
    "N_CELLS_HOR = 160\n",
    "N_CELLS_VER = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9591, 1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "celled_data = torch.load(\"Data/celled_data_\"\n",
    "                         + str(N_CELLS_HOR)\n",
    "                         + \"x\"\n",
    "                         + str(N_CELLS_VER))\n",
    "print (celled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celled_data_RTL = torch.load(\"Data/RTL_features\")\n",
    "# print (celled_data_RTL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_day_image (tensor, day):\n",
    "    plt.imshow (tensor[day].squeeze(0), cmap=plt.cm.afmhot_r)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_one_day_quakes (tensor, day):\n",
    "    state = tensor[day].squeeze(0)\n",
    "    print (state.shape)\n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if (state[i][j] != 0):\n",
    "                X.append(i)\n",
    "                Y.append(j)\n",
    "                M.append(state[i][j].item())\n",
    "    print (X)\n",
    "    print (Y)\n",
    "    print (M)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    plt.axis([0, state.shape[0], 0, state.shape[1]])\n",
    "    axes.scatter(X, Y, s=500, c=M, marker='.', cmap=plt.cm.Reds)\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 200])\n",
      "[59, 70, 111, 119]\n",
      "[71, 69, 135, 142]\n",
      "[2.5, 2.5999999046325684, 3.700000047683716, 2.9000000953674316]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_one_day_quakes (celled_data, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:7\n"
     ]
    }
   ],
   "source": [
    "DEVICE_ID = 7\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "# DEVICE = torch.device('cpu')\n",
    "print (DEVICE)\n",
    "# torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy (input, target, threshold):\n",
    "    true = ((input>threshold) == target)\n",
    "    sum = torch.sum (true.float())\n",
    "    return sum/input.shape[0]/input.shape[1]/input.shape[2]/input.shape[3]\n",
    "\n",
    "def my_precision (input, target, threshold):\n",
    "    TP = torch.sum (((input>threshold) * target      ).float())\n",
    "    FP = torch.sum (((input>threshold) * (1 - target)).float())\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def my_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target).float())\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def my_precision_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold)  * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target      ).float())\n",
    "#     print ('TP = ', TP.item(), 'FP = ', FP.item(), 'FN = ', FN.item(), 'N = ', input.shape[0])\n",
    "    return TP / (TP + FP), TP / (TP + FN)\n",
    "\n",
    "def my_precision_TPR_FPR (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    TN = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return TP / (TP + FP), TP / (TP + FN), FP / (FP + TN)\n",
    "\n",
    "def my_TP_FN_FP_TN (input, target, threshold):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    matrix[0, 0] = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    matrix[1, 0] = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    matrix[0, 1] = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    matrix[1, 1] = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет\n",
    "#### (Может не влезть в оперативку (надо ~ 12Gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVED_DAYS = 64     # ~2 months\n",
    "DAYS_TO_PREDICT_AFTER  = 10\n",
    "DAYS_TO_PREDICT_BEFORE = 50\n",
    "TESTING_DAYS = 1000\n",
    "\n",
    "HEAVY_QUAKE_THRES = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = (celled_data>HEAVY_QUAKE_THRES).float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "print (mean_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeDataset_RNN_Usual_Train (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[0:\n",
    "                                (celled_data.shape[0] -\n",
    "                                 TESTING_DAYS)]\n",
    "        \n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        accurate_pred = ((torch.sum(self.data[(idx +\n",
    "                                              DAYS_TO_PREDICT_AFTER):\n",
    "                                             (idx +\n",
    "                                              DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                                   dim=0,\n",
    "                                   keepdim=True).squeeze(0) > 0).float()\n",
    "                         - mean_val)\n",
    "        return (self.data[(idx)],\n",
    "                torch.cat([1 - accurate_pred, accurate_pred], dim=0))\n",
    "        \n",
    "\n",
    "class EarthquakeDataset_RNN_Usual_Test (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[(celled_data.shape[0] -\n",
    "                                 TESTING_DAYS):\n",
    "                                (celled_data.shape[0])]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "    \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[(idx)],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EarthquakeDataset_RNN_Train (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[0:\n",
    "#                                 (celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS)]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[idx],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)\n",
    "        \n",
    "\n",
    "# class EarthquakeDataset_RNN_Test (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[(celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS):\n",
    "#                                 (celled_data.shape[0])]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[(idx)],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data : torch.Size([8591, 1, 160, 200])\n",
      "size      : 8541\n",
      "self.data : torch.Size([1000, 1, 160, 200])\n",
      "size      : 950\n"
     ]
    }
   ],
   "source": [
    "earthquakes_dataset_train = EarthquakeDataset_RNN_Usual_Train (celled_data)\n",
    "earthquakes_dataset_test  = EarthquakeDataset_RNN_Usual_Test  (celled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "\n",
    "earthquakes_dataloader_test  = DataLoader(earthquakes_dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим саму сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.CONV  = nn.Conv2d    (in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   bias=False)             # think about it later\n",
    "        \n",
    "        self.BNORM =nn.BatchNorm2d(out_channels,\n",
    "                                   eps=1e-05,\n",
    "                                   momentum=0.1,\n",
    "                                   affine=False)\n",
    "#         self.RELU  = nn.ReLU ()\n",
    "        \n",
    "#         self.MAXPOOL = nn.MaxPool2d(3,\n",
    "#                                     stride=1,\n",
    "#                                     padding=1,\n",
    "#                                     dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('sizeof(x) = ', x.size())\n",
    "        #print ('sizeof(xprev) = ', xprev.size())    \n",
    "        \n",
    "        x = self.CONV   (x)\n",
    "        x = self.BNORM  (x)\n",
    "#         x = self.RELU   (x)\n",
    "#         x = self.MAXPOOL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySoftMax (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        x = x.exp()\n",
    "        return x / x.sum(dim=(1, 2), keepdim=True)\n",
    "        \n",
    "\n",
    "class SelfAttention (nn.Module):\n",
    "    \n",
    "    def __init__ (self, emb_size, query_key_size, value_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_size       = emb_size\n",
    "        self.query_key_size = query_key_size\n",
    "        self.value_size     = value_size\n",
    "        \n",
    "        self.emb_to_query = nn.Linear(emb_size, query_key_size)\n",
    "        self.emb_to_key   = nn.Linear(emb_size, query_key_size)\n",
    "        self.emb_to_value = nn.Linear(emb_size, value_size)\n",
    "        \n",
    "        self.softmax = MySoftMax()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        \n",
    "        emb = x.permute((0, 2, 3, 1))\n",
    "        \n",
    "#         print (emb.shape)\n",
    "        \n",
    "        queries = self.emb_to_query(emb)\n",
    "        keys    = self.emb_to_key  (emb)\n",
    "        values  = self.emb_to_value(emb)\n",
    "        \n",
    "        ret = torch.empty_like(values)\n",
    "        \n",
    "        for i in range(queries.shape[1]):\n",
    "#             print (\"My i = \", i)\n",
    "            for j in range(queries.shape[2]):\n",
    "                \n",
    "                weights = torch.sum(keys * queries[:, i, j, :].unsqueeze(1).unsqueeze(1),\n",
    "                                    dim=3)\n",
    "                weights /= self.query_key_size\n",
    "                weights = self.softmax(weights)\n",
    "                \n",
    "                weighted_values = values * weights.unsqueeze(3)\n",
    "                \n",
    "                ret[:, i, j, :] = weighted_values.sum(dim=(1, 2))\n",
    "        \n",
    "        return ret.permute((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding (nn.Module):\n",
    "    def __init__(self, n_mod, denom):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_mod = n_mod\n",
    "        self.denom = denom\n",
    "        \n",
    "        self.carriers = 1 / torch.pow(denom, (torch.arange(n_mod, dtype=torch.float, device=DEVICE) + 1) / n_mod)\n",
    "        \n",
    "    def make_PE_matrix (self, hor_len, ver_len):\n",
    "        \n",
    "        matrix = torch.ones([self.n_mod, hor_len, ver_len], dtype=torch.float, device=DEVICE)\n",
    "        matrix = matrix * self.carriers.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        hor_positions = torch.arange(hor_len, dtype=torch.float, device=DEVICE).unsqueeze(1)\n",
    "        ver_positions = torch.arange(ver_len, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
    "        \n",
    "        matrix_hor = matrix * hor_positions.unsqueeze(0)\n",
    "        matrix_ver = matrix * ver_positions.unsqueeze(0)\n",
    "        \n",
    "        for i in range(self.n_mod):\n",
    "            if   i%2 == 0:\n",
    "                matrix[i, :, :] = (torch.sin(matrix_hor[i, :, :]) * \n",
    "                                   torch.sin(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 1:\n",
    "                matrix[i, :, :] = (torch.sin(matrix_hor[i, :, :]) * \n",
    "                                   torch.cos(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 2:\n",
    "                matrix[i, :, :] = (torch.cos(matrix_hor[i, :, :]) * \n",
    "                                   torch.sin(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 3:\n",
    "                matrix[i, :, :] = (torch.cos(matrix_hor[i, :, :]) * \n",
    "                                   torch.cos(matrix_ver[i, :, :]))    \n",
    "        return matrix\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.ones((2, 5, 5))\n",
    "\n",
    "# # softmax = nn.Softmax2d()\n",
    "\n",
    "# # a = softmax(a)\n",
    "\n",
    "# a = a.unsqueeze(-1)\n",
    "\n",
    "# print (a.shape)\n",
    "# print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell (nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size=16, hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.  h_size = hidden_state_size\n",
    "        \n",
    "        self.embedding  = ConvBlock (1, embedding_size, 3)\n",
    "        self.RNN_update = nn.Sequential (ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size + embedding_size,\n",
    "                                                    kernel_size=3),\n",
    "                                         ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size,\n",
    "                                                    kernel_size=3))\n",
    "        self.RNN_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                       2, \n",
    "                                                       kernel_size=3),\n",
    "                                            nn.Softmax (dim=1))\n",
    "        \n",
    "    def forward (self, x, h_prev):\n",
    "        \n",
    "        x_emb   = self.embedding (x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
    "#         print (\"x_and_h : \", x_and_h.shape)\n",
    "        h_next  = self.RNN_update(x_and_h)\n",
    "#         print (\"h_prev :\", h_prev.shape)\n",
    "#         print (\"h_next :\", h_next.shape)\n",
    "        \n",
    "        assert h_prev.shape == h_next.shape\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        result = self.RNN_to_result(h_next)\n",
    "        return h_next, result\n",
    "    \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return torch.zeros(batch_size,\n",
    "                           self.h_size,\n",
    "                           N_CELLS_HOR, \n",
    "                           N_CELLS_VER,\n",
    "                           requires_grad=False,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "![LSTM](./img/LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell (nn.Module):\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  embedding_size=16,\n",
    "                  hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.hid_size = hidden_state_size\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(embedding_size, 250 / m.pi / 2)\n",
    "        \n",
    "        self.PE_matrix = self.pos_encoding.make_PE_matrix(N_CELLS_HOR, N_CELLS_VER)\n",
    "        \n",
    "        self.self_attention = SelfAttention(emb_size=embedding_size,\n",
    "                                            query_key_size=embedding_size,\n",
    "                                            value_size=embedding_size)\n",
    "                \n",
    "#         self.embedding = ConvBlock (1, self.emb_size, kernel_size=3)\n",
    "        self.embedding = nn.Sequential(ConvBlock(1,\n",
    "                                                 self.emb_size,\n",
    "                                                 3),\n",
    "                                       nn.ReLU(),\n",
    "                                       ConvBlock(self.emb_size,\n",
    "                                                 self.emb_size,\n",
    "                                                 3))\n",
    "    \n",
    "        self.hidden_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                          2, \n",
    "                                                          kernel_size=3),\n",
    "                                               nn.Softmax (dim=1))\n",
    "        \n",
    "        self.f_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.i_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.c_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Tanh())\n",
    "        self.o_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        \n",
    "        (prev_c, prev_h) = prev_state\n",
    "        x_emb = self.embedding(x)\n",
    "#         print (x_emb.shape)\n",
    "        x_emb = x_emb + self.self_attention(x_emb)\n",
    "        \n",
    "        x_and_h = torch.cat([prev_h, x_emb], dim=1)\n",
    "        \n",
    "        f_i = self.f_t(x_and_h)\n",
    "        i_i = self.i_t(x_and_h)\n",
    "        c_i = self.c_t(x_and_h)\n",
    "        o_i = self.o_t(x_and_h)\n",
    "        \n",
    "        next_c = prev_c * f_i + i_i * c_i\n",
    "        next_h = torch.tanh(next_c) * o_i\n",
    "        \n",
    "        assert prev_h.shape == next_h.shape\n",
    "        assert prev_c.shape == next_c.shape\n",
    "        \n",
    "        return (next_c, next_h), self.hidden_to_result(next_h)\n",
    "        \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)),\n",
    "                Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)))\n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция тренеровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossEntropy(weights, prediction, target):\n",
    "    assert len(weights) == prediction.shape[1]\n",
    "    assert prediction.shape == target.shape\n",
    "    loss = 0\n",
    "    \n",
    "#     print (prediction.shape)\n",
    "#     print ((prediction>0).sum().item())\n",
    "#     print ((prediction<0).sum().item())\n",
    "#     print ((prediction==0).sum().item())\n",
    "    \n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(len(weights)):\n",
    "            loss -= weights[j] * torch.sum(target[i, j] * prediction[i, j].log())\n",
    "    return loss / prediction.shape[2] / prediction.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN (RNN_cell,\n",
    "                       device,\n",
    "                       dataloader_train,\n",
    "                       n_cycles=1,\n",
    "                       learning_rate=0.0003,\n",
    "                       earthquake_weight=1.,\n",
    "                       lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for cycle in range(n_cycles):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "#         optimizer = torch.optim.SGD(RNN_cell.parameters(), lr=learning_rate)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "#         for data in tqdm(dataloader_train):\n",
    "        for data in dataloader_train:\n",
    "            \n",
    "#             print (\"step No \", i)\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "#             print (\"inputs\", inputs.shape)\n",
    "#             print (\"hid_state\", hid_state.shape)\n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "            loss = my_crossEntropy(weights, outputs, labels)\n",
    "#             print (\"Loss : \", loss.item())\n",
    "            if (m.isnan(loss.item())):\n",
    "                print (\"We have NaN !!!!!!!!!!\")\n",
    "                break\n",
    "            loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "            if (type(hid_state) == tuple):\n",
    "                for elem in hid_state:\n",
    "                    elem.detach_()\n",
    "            else:\n",
    "                hid_state.detach_()\n",
    "            \n",
    "            if (i)%100==0:\n",
    "                clear_output(True)\n",
    "                print (\"Done :\", i, \"/\", dataloader_train.__len__())\n",
    "                plt.plot(loss_massive,label='loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "            os.mkdir(READY_DIR + str(i))\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "        learning_rate /= lr_decay\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CYCLES = 1\n",
    "LEARNING_RATE = 0.0003\n",
    "LR_DECAY = 10.\n",
    "EARTHQUAKE_WEIGHT = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "HID_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN_cell = RNNCell()\n",
    "RNN_cell = LSTMCell(embedding_size    = EMB_SIZE,\n",
    "                    hidden_state_size = HID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done : 0 / 8541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_cell.apply(init_weights)\n",
    "train_network_RNN (RNN_cell,\n",
    "                   DEVICE,\n",
    "                   earthquakes_dataloader_train,\n",
    "                   n_cycles=N_CYCLES,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                   lr_decay=LR_DECAY\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(READY_DIR + 'Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality (RNN_cell,\n",
    "                   device,\n",
    "                   dataloader_test,\n",
    "                   n_dots=501,\n",
    "                   info_file=None):\n",
    "    \n",
    "    prediction = torch.zeros(dataloader_test.__len__(),  N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    prediction.detach_()\n",
    "    target     = torch.zeros(dataloader_test.__len__(), N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    target.detach_()\n",
    "       \n",
    "    RNN_cell.to(device)\n",
    "\n",
    "    hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "    if (type(hid_state) == tuple):\n",
    "        for elem in hid_state:\n",
    "            elem.detach_()\n",
    "    else:\n",
    "        hid_state.detach_()\n",
    "        \n",
    "    i = 0\n",
    "    for data in tqdm(dataloader_test):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device).float()\n",
    "\n",
    "        hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "        \n",
    "        prediction[i] = outputs[:, 1, :, :]\n",
    "        target    [i] = labels.squeeze(0)\n",
    "    \n",
    "        if (type(hid_state) == tuple):\n",
    "            for elem in hid_state:\n",
    "                elem.detach_()\n",
    "        else:\n",
    "            hid_state.detach_()\n",
    "        prediction.detach_()\n",
    "        target    .detach_()\n",
    "        i += 1\n",
    "        \n",
    "    assert prediction.shape == target.shape\n",
    "    prediction = prediction [10:prediction.shape[0]]  # cutting peace of data because\n",
    "    prediction += mean_val.to(device)\n",
    "    target     = target     [10:target    .shape[0]]  # hidden state might be not good\n",
    "    \n",
    "    print (\"ROC_AUC_score = \", end='')\n",
    "    ROC_AUC_score = roc_auc_score(np.array(target    .view(-1).cpu()),\n",
    "                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (ROC_AUC_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('ROC_AUC               =', ROC_AUC_score, file=info_file)\n",
    "    \n",
    "    print (\"AVG_precision_score = \", end='')\n",
    "    AVG_precision_score = average_precision_score(np.array(target    .view(-1).cpu()),\n",
    "                                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (AVG_precision_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('Average_precision     =', AVG_precision_score, file=info_file)\n",
    "        \n",
    "    print ('\\n=======================')\n",
    "    \n",
    "    for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "        print ('Threshold = ', threshold)\n",
    "        print ('-----------------------')\n",
    "        print (my_TP_FN_FP_TN(prediction, target, threshold))\n",
    "        print ('=======================')\n",
    "    \n",
    "    if SAVE_INFO:\n",
    "        print ('\\n=======================', file=info_file)\n",
    "    \n",
    "        for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "            print ('Threshold = ', threshold                    , file=info_file)\n",
    "            print ('-----------------------'                    , file=info_file)\n",
    "            print (my_TP_FN_FP_TN(prediction, target, threshold), file=info_file)\n",
    "            print ('======================='                    , file=info_file)\n",
    "    \n",
    "    threshold_massive = torch.linspace (0, 1, n_dots, dtype=torch.float, device=device)\n",
    "    \n",
    "#     precision = np.zeros(n_dots)\n",
    "#     recall    = np.zeros(n_dots)\n",
    "#     FPR       = np.zeros(n_dots)\n",
    "\n",
    "    precision_massive = []\n",
    "    recall_massive    = []\n",
    "    FPR_massive       = []\n",
    "    \n",
    "    for threshold in tqdm(threshold_massive):\n",
    "        precision, recall, FPR = my_precision_TPR_FPR(prediction, target, threshold)\n",
    "        precision_massive.append(precision.item())\n",
    "        recall_massive   .append(recall.item())\n",
    "        FPR_massive      .append(FPR.item())\n",
    "    \n",
    "    # plot 1 precision\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), precision_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('precision')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2 recall\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), recall_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('recall')\n",
    "    \n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 3 ROC-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(FPR_massive, recall_massive, 'orange', marker = '^')\n",
    "    axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "    axes.set_xlabel('FPR')\n",
    "    axes.set_ylabel('TPR (recall)')\n",
    "    axes.set_title('ROC-curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 4 precision-recall-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(recall_massive, precision_massive, 'orange', marker = '^')\n",
    "\n",
    "    axes.set_xlabel('Recall')\n",
    "    axes.set_ylabel('Precision')\n",
    "    axes.set_title('Precision_Recall_curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_Recall_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    return ROC_AUC_score, AVG_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_INFO_to_file(info_file):\n",
    "        \n",
    "    print ('LEFT_BORDER           =', LEFT_BORDER                           , file=info_file)\n",
    "    print ('RIGHT_BORDER          =', RIGHT_BORDER                          , file=info_file)\n",
    "    print ('DOWN_BORDER           =', DOWN_BORDER                           , file=info_file)\n",
    "    print ('UP_BORDER             =', UP_BORDER                             , file=info_file)\n",
    "    print ('N_CELLS_HOR           =', N_CELLS_HOR                           , file=info_file)\n",
    "    print ('N_CELLS_VER           =', N_CELLS_VER                           , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('OBSERVED_DAYS         =', OBSERVED_DAYS                         , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_AFTER =', DAYS_TO_PREDICT_AFTER                 , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_BEFOR =', DAYS_TO_PREDICT_BEFORE                , file=info_file)\n",
    "    print ('TESTING_DAYS          =', TESTING_DAYS                          , file=info_file)\n",
    "    print ('HEAVY_QUAKE_THRES     =', HEAVY_QUAKE_THRES                     , file=info_file)\n",
    "    print ('LEARNING_RATE         =', LEARNING_RATE                         , file=info_file)\n",
    "    print ('LR_DECAY              =', LR_DECAY                              , file=info_file)\n",
    "    print ('N_CYCLES              =', N_CYCLES                              , file=info_file)\n",
    "    print ('EARTHQUAKE_WEIGHT     =', EARTHQUAKE_WEIGHT                     , file=info_file)\n",
    "    print ('TRAIN_SHAPE           =', earthquakes_dataset_train.data.shape  , file=info_file)\n",
    "    print ('TEST__SHAPE           =', earthquakes_dataset_test .data.shape  , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('EMB_SIZE              =', EMB_SIZE                              , file=info_file)\n",
    "    print ('HID_SIZE              =', HID_SIZE                              , file=info_file)\n",
    "    \n",
    "    \n",
    "#         print ('', , file=info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    RNN_cell.eval()\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        info_file = open (EXPERIMENT_DIR + 'INFO.txt', 'w')\n",
    "    else:\n",
    "        info_file = None\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        print_INFO_to_file(info_file)\n",
    "\n",
    "    ROC_AUC, AVG_prec = check_quality (RNN_cell,\n",
    "                                       DEVICE,\n",
    "                                       earthquakes_dataloader_test,\n",
    "                                       n_dots=251,\n",
    "                                       info_file=info_file)\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        info_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
