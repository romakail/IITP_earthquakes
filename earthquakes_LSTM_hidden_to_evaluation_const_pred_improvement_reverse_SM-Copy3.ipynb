{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INFO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAVE_INFO == True):\n",
    "    DATA_DIR = 'Experiments/'\n",
    "    EXPERIMENT_DIR = DATA_DIR + 'h_rev_SM_fin_1000/'\n",
    "    os.makedirs(EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета по дням и по клеткам в сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_BORDER = 0\n",
    "RIGHT_BORDER = 2000\n",
    "DOWN_BORDER = 0\n",
    "UP_BORDER = 2500\n",
    "\n",
    "N_CELLS_HOR = 200\n",
    "N_CELLS_VER = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9591, 1, 200, 250])\n"
     ]
    }
   ],
   "source": [
    "celled_data = torch.load(\"Data/celled_data_\"\n",
    "                         + str(N_CELLS_HOR)\n",
    "                         + \"x\"\n",
    "                         + str(N_CELLS_VER))\n",
    "print (celled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_one_day_image (tensor, day):\n",
    "    plt.imshow (tensor[day].squeeze(0), cmap=plt.cm.afmhot_r)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_one_day_quakes (tensor, day):\n",
    "    state = tensor[day].squeeze(0)\n",
    "    print (state.shape)\n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if (state[i][j] != 0):\n",
    "                X.append(i)\n",
    "                Y.append(j)\n",
    "                M.append(state[i][j].item())\n",
    "    print (X)\n",
    "    print (Y)\n",
    "    print (M)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    plt.axis([0, state.shape[0], 0, state.shape[1]])\n",
    "    axes.scatter(X, Y, s=500, c=M, marker='.', cmap=plt.cm.Reds)\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 250])\n",
      "[74, 88, 138, 149]\n",
      "[89, 87, 169, 177]\n",
      "[2.5, 2.5999999046325684, 3.700000047683716, 2.9000000953674316]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_one_day_quakes (celled_data, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE_ID = 1\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "print (DEVICE)\n",
    "# torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy (input, target, threshold):\n",
    "    true = ((input>threshold) == target)\n",
    "    sum = torch.sum (true.float())\n",
    "    return sum/input.shape[0]/input.shape[1]/input.shape[2]/input.shape[3]\n",
    "\n",
    "def my_precision (input, target, threshold):\n",
    "    TP = torch.sum (((input>threshold) * target      ).float())\n",
    "    FP = torch.sum (((input>threshold) * (1 - target)).float())\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def my_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target).float())\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def my_precision_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold)  * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target      ).float())\n",
    "#     print ('TP = ', TP.item(), 'FP = ', FP.item(), 'FN = ', FN.item(), 'N = ', input.shape[0])\n",
    "    return TP / (TP + FP), TP / (TP + FN)\n",
    "\n",
    "def my_precision_TPR_FPR (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    TN = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return TP / (TP + FP), TP / (TP + FN), FP / (FP + TN)\n",
    "\n",
    "def my_TP_FN_FP_TN (input, target, threshold):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    matrix[0, 0] = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    matrix[1, 0] = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    matrix[0, 1] = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    matrix[1, 1] = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет\n",
    "#### (Может не влезть в оперативку (надо ~ 12Gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVED_DAYS = 64     # ~2 months\n",
    "DAYS_TO_PREDICT_AFTER  = 10\n",
    "DAYS_TO_PREDICT_BEFORE = 50\n",
    "TESTING_DAYS = 1000\n",
    "\n",
    "HEAVY_QUAKE_THRES = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = (celled_data>HEAVY_QUAKE_THRES).float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 250])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa25d9bc978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (mean_val.shape)\n",
    "plt.imshow(mean_val[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeDataset_RNN_Train (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[0:\n",
    "                                (celled_data.shape[0] -\n",
    "                                 TESTING_DAYS)]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)\n",
    "        \n",
    "\n",
    "class EarthquakeDataset_RNN_Test (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[(celled_data.shape[0] -\n",
    "                                 TESTING_DAYS):\n",
    "                                (celled_data.shape[0])]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[(idx)],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data : torch.Size([8591, 1, 200, 250])\n",
      "size      : 8541\n",
      "self.data : torch.Size([1000, 1, 200, 250])\n",
      "size      : 950\n"
     ]
    }
   ],
   "source": [
    "earthquakes_dataset_train = EarthquakeDataset_RNN_Train (celled_data)\n",
    "earthquakes_dataset_test  = EarthquakeDataset_RNN_Test  (celled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "\n",
    "earthquakes_dataloader_test  = DataLoader(earthquakes_dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим саму сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.CONV  = nn.Conv2d    (in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   bias=False)             # think about it later\n",
    "        \n",
    "        self.BNORM =nn.BatchNorm2d(out_channels,\n",
    "                                   eps=1e-05,\n",
    "                                   momentum=0.1,\n",
    "                                   affine=False)\n",
    "#         self.RELU  = nn.ReLU ()\n",
    "        \n",
    "#         self.MAXPOOL = nn.MaxPool2d(3,\n",
    "#                                     stride=1,\n",
    "#                                     padding=1,\n",
    "#                                     dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('sizeof(x) = ', x.size())\n",
    "        #print ('sizeof(xprev) = ', xprev.size())    \n",
    "        \n",
    "        x = self.CONV   (x)\n",
    "        x = self.BNORM  (x)\n",
    "#         x = self.RELU   (x)\n",
    "#         x = self.MAXPOOL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "![LSTM](./img/LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell (nn.Module):\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  mean_val,\n",
    "                  embedding_size=16,\n",
    "                  hidden_state_size=32,\n",
    "                  reverse_log_bias=0,\n",
    "                  device=torch.device('cpu')):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.hid_size = hidden_state_size\n",
    "        \n",
    "        self.mean_val = mean_val.to(device)\n",
    "        self.prior = torch.log(torch.cat([1-mean_val, mean_val], dim=0)).to(device).unsqueeze(0)\n",
    "        self.prior = self.prior + reverse_log_bias\n",
    "        \n",
    "#         self.embedding = ConvBlock (1, self.emb_size, kernel_size=3)\n",
    "        self.embedding = nn.Sequential(ConvBlock(1,\n",
    "                                                 self.emb_size,\n",
    "                                                 3),\n",
    "                                       nn.ReLU(),\n",
    "                                       ConvBlock(self.emb_size,\n",
    "                                                 self.emb_size,\n",
    "                                                 3))\n",
    "        self.hidden_to_result = ConvBlock(hidden_state_size, \n",
    "                                          2, \n",
    "                                          kernel_size=3)\n",
    "        \n",
    "        self.out_activation = nn.Softmax (dim=1)\n",
    "        \n",
    "        self.f_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.i_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.c_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Tanh())\n",
    "        self.o_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        (prev_c, prev_h) = prev_state\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        x_and_h = torch.cat([prev_h, x_emb], dim=1)\n",
    "        \n",
    "        f_i = self.f_t(x_and_h)\n",
    "        i_i = self.i_t(x_and_h)\n",
    "        c_i = self.c_t(x_and_h)\n",
    "        o_i = self.o_t(x_and_h)\n",
    "        \n",
    "        next_c = prev_c * f_i + i_i * c_i\n",
    "        next_h = torch.tanh(next_c) * o_i\n",
    "        \n",
    "        assert prev_h.shape == next_h.shape\n",
    "        assert prev_c.shape == next_c.shape\n",
    "        \n",
    "        out = self.hidden_to_result(next_h)\n",
    "        \n",
    "        return (next_c, next_h), self.out_activation(self.prior + out)\n",
    "        \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)),\n",
    "                Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)))\n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция тренеровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN (RNN_cell,\n",
    "                       device,\n",
    "                       dataloader_train,\n",
    "                       n_cycles=1,\n",
    "                       learning_rate=0.0003,\n",
    "                       earthquake_weight=1.,\n",
    "                       lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for cycle in range(n_cycles):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "#         for data in tqdm(dataloader_train):\n",
    "        for data in dataloader_train:\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "#             print (\"inputs\", inputs.shape)\n",
    "#             print (\"hid_state\", hid_state.shape)\n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "            loss = criterion(outputs, labels.squeeze(1).long())\n",
    "#             loss = my_crossEntropy(weights, outputs, labels)\n",
    "            loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "            if (type(hid_state) == tuple):\n",
    "                for elem in hid_state:\n",
    "                    elem.detach_()\n",
    "            else:\n",
    "                hid_state.detach_()\n",
    "            \n",
    "            if (i)%100==0:\n",
    "                clear_output(True)\n",
    "                print (\"Done :\", i, \"/\", dataloader_train.__len__())\n",
    "                plt.plot(loss_massive,label='loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            i += 1\n",
    "        learning_rate /= lr_decay\n",
    "    return hid_state\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN_grad(RNN_cell,\n",
    "                           device,\n",
    "                           dataset_train,\n",
    "                           n_runs=1,\n",
    "                           run_len=10,\n",
    "                           learning_rate=0.0003,\n",
    "                           earthquake_weight=1.,\n",
    "                           lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for run in range(n_runs):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "        # Better figure out whether the hidden changes\n",
    "        \n",
    "        start = random.randint(0, \n",
    "                               dataset_train.__len__() - \n",
    "                               run_len - 1)\n",
    "        \n",
    "#         for data in dataloader_train:\n",
    "        for idx in range(start, start + run_len):\n",
    "            \n",
    "            inputs = dataset_train[idx][0].to(device).unsqueeze(0)\n",
    "            labels = dataset_train[idx][1].to(device)\n",
    "            \n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "#             loss = my_crossEntropy(weights, outputs, labels)\n",
    "#             loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels.squeeze(1).long())\n",
    "        loss_massive.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "#             if (type(hid_state) == tuple):\n",
    "#                 for elem in hid_state:\n",
    "#                     elem.detach_()\n",
    "#             else:\n",
    "#                 hid_state.detach_()\n",
    "            \n",
    "        if (i)%5==0:\n",
    "            clear_output(True)\n",
    "            print (\"Done :\", i, \"/\", dataset_train.__len__())\n",
    "            plt.plot(loss_massive,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        i += 1\n",
    "        learning_rate /= lr_decay\n",
    "    return hid_state\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CYCLES = 1\n",
    "N_RUNS = 300\n",
    "RUN_LEN = 150\n",
    "LEARNING_RATE = 0.0003\n",
    "LR_DECAY = 10.\n",
    "EARTHQUAKE_WEIGHT = 1000.\n",
    "REVERSE_LOG_BIAS = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "HID_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done : 0 / 8541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_cell = LSTMCell(mean_val,\n",
    "                    embedding_size    = EMB_SIZE,\n",
    "                    hidden_state_size = HID_SIZE,\n",
    "                    reverse_log_bias  = REVERSE_LOG_BIAS,\n",
    "                    device=DEVICE)\n",
    "hid_state = train_network_RNN (RNN_cell,\n",
    "                               DEVICE,\n",
    "                               earthquakes_dataloader_train,\n",
    "                               n_cycles=N_CYCLES,\n",
    "                               learning_rate=LEARNING_RATE,\n",
    "                               earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                               lr_decay=LR_DECAY\n",
    "                               )\n",
    "train_network_RNN_grad(RNN_cell,\n",
    "                       DEVICE,\n",
    "                       earthquakes_dataset_train,\n",
    "                       n_runs=N_RUNS,\n",
    "                       run_len=RUN_LEN,\n",
    "                       learning_rate=LEARNING_RATE,\n",
    "                       earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                       lr_decay=LR_DECAY\n",
    "                       )\n",
    "hid_state = train_network_RNN (RNN_cell,\n",
    "                               DEVICE,\n",
    "                               earthquakes_dataloader_train,\n",
    "                               n_cycles=N_CYCLES,\n",
    "                               learning_rate=LEARNING_RATE,\n",
    "                               earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                               lr_decay=LR_DECAY\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def check_quality (RNN_cell,\n",
    "                   device,\n",
    "                   dataloader_test,\n",
    "                   hid_state,\n",
    "                   n_dots=501,\n",
    "                   info_file=None):\n",
    "    \n",
    "    prediction = torch.zeros(dataloader_test.__len__(),  N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    prediction.detach_()\n",
    "    target     = torch.zeros(dataloader_test.__len__(), N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    target.detach_()\n",
    "       \n",
    "    RNN_cell.to(device)\n",
    "\n",
    "    hid_state = hid_state\n",
    "    if (type(hid_state) == tuple):\n",
    "        for elem in hid_state:\n",
    "            elem.detach_()\n",
    "    else:\n",
    "        hid_state.detach_()\n",
    "        \n",
    "    i = 0\n",
    "    for data in tqdm(dataloader_test):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device).float()\n",
    "\n",
    "        hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "        \n",
    "        prediction[i] = outputs[:, 1, :, :]\n",
    "        target    [i] = labels.squeeze(0)\n",
    "    \n",
    "        if (type(hid_state) == tuple):\n",
    "            for elem in hid_state:\n",
    "                elem.detach_()\n",
    "        else:\n",
    "            hid_state.detach_()\n",
    "        prediction.detach_()\n",
    "        target    .detach_()\n",
    "        i += 1\n",
    "        \n",
    "    assert prediction.shape == target.shape\n",
    "#     prediction = prediction [10:prediction.shape[0]]  # cutting peace of data because\n",
    "#     target     = target     [10:target    .shape[0]]  # hidden state might be not good\n",
    "    \n",
    "    print (\"ROC_AUC_score = \", end='')\n",
    "    ROC_AUC_score = roc_auc_score(np.array(target    .view(-1).cpu()),\n",
    "                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (ROC_AUC_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('ROC_AUC               =', ROC_AUC_score, file=info_file)\n",
    "    \n",
    "    print (\"AVG_precision_score = \", end='')\n",
    "    AVG_precision_score = average_precision_score(np.array(target    .view(-1).cpu()),\n",
    "                                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (AVG_precision_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('Average_precision     =', AVG_precision_score, file=info_file)\n",
    "        \n",
    "    print ('\\n=======================')\n",
    "    \n",
    "    for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "        print ('Threshold = ', threshold)\n",
    "        print ('-----------------------')\n",
    "        print (my_TP_FN_FP_TN(prediction, target, threshold))\n",
    "        print ('=======================')\n",
    "    \n",
    "    if SAVE_INFO:\n",
    "        print ('\\n=======================', file=info_file)\n",
    "    \n",
    "        for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "            print ('Threshold = ', threshold                    , file=info_file)\n",
    "            print ('-----------------------'                    , file=info_file)\n",
    "            print (my_TP_FN_FP_TN(prediction, target, threshold), file=info_file)\n",
    "            print ('======================='                    , file=info_file)\n",
    "    \n",
    "    threshold_massive = torch.linspace (0, 1, n_dots, dtype=torch.float, device=device)\n",
    "    \n",
    "#     precision = np.zeros(n_dots)\n",
    "#     recall    = np.zeros(n_dots)\n",
    "#     FPR       = np.zeros(n_dots)\n",
    "\n",
    "    precision_massive = []\n",
    "    recall_massive    = []\n",
    "    FPR_massive       = []\n",
    "    \n",
    "    for threshold in tqdm(threshold_massive):\n",
    "        precision, recall, FPR = my_precision_TPR_FPR(prediction, target, threshold)\n",
    "        precision_massive.append(precision.item())\n",
    "        recall_massive   .append(recall.item())\n",
    "        FPR_massive      .append(FPR.item())\n",
    "    \n",
    "    # plot 1 precision\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), precision_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('precision')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2 recall\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), recall_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('recall')\n",
    "    \n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 3 ROC-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(FPR_massive, recall_massive, 'orange', marker = '^')\n",
    "    axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "    axes.set_xlabel('FPR')\n",
    "    axes.set_ylabel('TPR (recall)')\n",
    "    axes.set_title('ROC-curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 4 precision-recall-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(recall_massive, precision_massive, 'orange', marker = '^')\n",
    "\n",
    "    axes.set_xlabel('Recall')\n",
    "    axes.set_ylabel('Precision')\n",
    "    axes.set_title('Precision_Recall_curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_Recall_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    return ROC_AUC_score, AVG_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_INFO_to_file(info_file):\n",
    "        \n",
    "    print ('LEFT_BORDER           =', LEFT_BORDER                           , file=info_file)\n",
    "    print ('RIGHT_BORDER          =', RIGHT_BORDER                          , file=info_file)\n",
    "    print ('DOWN_BORDER           =', DOWN_BORDER                           , file=info_file)\n",
    "    print ('UP_BORDER             =', UP_BORDER                             , file=info_file)\n",
    "    print ('N_CELLS_HOR           =', N_CELLS_HOR                           , file=info_file)\n",
    "    print ('N_CELLS_VER           =', N_CELLS_VER                           , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('OBSERVED_DAYS         =', OBSERVED_DAYS                         , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_AFTER =', DAYS_TO_PREDICT_AFTER                 , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_BEFOR =', DAYS_TO_PREDICT_BEFORE                , file=info_file)\n",
    "    print ('TESTING_DAYS          =', TESTING_DAYS                          , file=info_file)\n",
    "    print ('HEAVY_QUAKE_THRES     =', HEAVY_QUAKE_THRES                     , file=info_file)\n",
    "    print ('LEARNING_RATE         =', LEARNING_RATE                         , file=info_file)\n",
    "    print ('LR_DECAY              =', LR_DECAY                              , file=info_file)\n",
    "    print ('N_CYCLES              =', N_CYCLES                              , file=info_file)\n",
    "    print ('N_RUNS                =', N_RUNS                                , file=info_file)\n",
    "    print ('RUN_LEN               =', RUN_LEN                               , file=info_file)\n",
    "    print ('EARTHQUAKE_WEIGHT     =', EARTHQUAKE_WEIGHT                     , file=info_file)\n",
    "    print ('REVERSE_LOG_BIAS      =', REVERSE_LOG_BIAS                      , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('TRAIN_SHAPE           =', earthquakes_dataset_train.data.shape  , file=info_file)\n",
    "    print ('TEST__SHAPE           =', earthquakes_dataset_test .data.shape  , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('EMB_SIZE              =', EMB_SIZE                              , file=info_file)\n",
    "    print ('HID_SIZE              =', HID_SIZE                              , file=info_file)\n",
    "    \n",
    "    \n",
    "#         print ('', , file=info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_cell.eval()\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file = open (EXPERIMENT_DIR + 'INFO.txt', 'w')\n",
    "else:\n",
    "    info_file = None\n",
    "\n",
    "if SAVE_INFO:\n",
    "    print_INFO_to_file(info_file)\n",
    "    \n",
    "ROC_AUC, AVG_prec = check_quality (RNN_cell,\n",
    "                                   DEVICE,\n",
    "                                   earthquakes_dataloader_test,\n",
    "                                   hid_state,\n",
    "                                   n_dots=251,\n",
    "                                   info_file=info_file)\n",
    "\n",
    "if SAVE_INFO:\n",
    "    info_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_CE (network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=200,\n",
    "#                       learning_rate=0.1,\n",
    "#                       earthquake_weight=1.):\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file = open (EXPERIMENT_DIR + 'Epochs_info.txt', 'w')\n",
    "    \n",
    "#     loss_acc  = []\n",
    "#     test_acc  = []\n",
    "#     test_prec = []\n",
    "#     test_rec  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     weights = torch.tensor([1., earthquake_weight], dtype = torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9)\n",
    "#             print ('Changed learning rate to ', learning_rate/10)\n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "#             print ('Changed learning rate to ', learning_rate/100)\n",
    "            \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.shape, outputs.dtype)\n",
    "# #             print ('labels  : ', labels.shape , labels.dtype)\n",
    "# #             outputs = torch.cat ((1-outputs, outputs), dim=1)\n",
    "# #             print ('outputs ', outputs.shape, '   [', outputs[1, 0, 12, 12], outputs[1, 1, 12, 12], ']')\n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         loss_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "# #         calculating test accuracy, precision and recall\n",
    "#         epoch_accuracy  = 0.0\n",
    "#         epoch_precision = 0.0\n",
    "#         epoch_recall    = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "# #             find_mistake(outputs)\n",
    "#             accuracy = my_accuracy (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "#             precision, recall = my_precision_recall (outputs[:, 1, :, :].unsqueeze(1), labels, 0.5)\n",
    "# #             accuracy2 = my_accuracy (outputs, labels, 1.0)\n",
    "            \n",
    "#             epoch_elems     += labels.shape[0]\n",
    "#             epoch_accuracy  += accuracy.item()  * labels.shape[0]\n",
    "#             epoch_precision += precision.item() * labels.shape[0]\n",
    "#             epoch_recall    += recall.item()    * labels.shape[0]\n",
    "\n",
    "# #         epoch_accuracy /= epoch_elems\n",
    "#         test_acc .append (epoch_accuracy  / epoch_elems)\n",
    "#         test_prec.append (epoch_precision / epoch_elems)\n",
    "#         test_rec .append (epoch_recall    / epoch_elems)\n",
    "        \n",
    "        \n",
    "#         print('Ep :', epoch,\n",
    "#               'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#               'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#               'prec_ts :' , round (test_prec[-1], 4),\n",
    "#               'rec_ts :'  , round (test_rec [-1], 4))\n",
    "        \n",
    "#         if (SAVE_INFO == True):\n",
    "#             print('Ep :', epoch,\n",
    "#                   'loss_tr :' , round (loss_acc [-1], 7),\n",
    "#                   'acc_ts :'  , round (test_acc [-1], 4),\n",
    "#                   'prec_ts :' , round (test_prec[-1], 4),\n",
    "#                   'rec_ts :'  , round (test_rec [-1], 4)\n",
    "#                   , file=epochs_file)\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "# #     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(loss_acc , label='Loss')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Loss_train.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_acc , label='Test Accuracy')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Accuracy_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_prec, label='Test Precision')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.plot(test_rec , label='Test Recall')\n",
    "#     plt.legend()\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_test.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         epochs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEARNING_RATE = 0.1\n",
    "# N_EPOCHS = 200\n",
    "# EARTHQUAKE_WEIGHT = 10000.\n",
    "\n",
    "# earthquake_network = ConvNetwork_CE ()\n",
    "# train_network_CE  (earthquake_network,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=N_EPOCHS,\n",
    "#                    learning_rate=LEARNING_RATE,\n",
    "#                    earthquake_weight=EARTHQUAKE_WEIGHT\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_ROCinfo (model, dataLoader, device, alpha=0.5, n_dots=101):\n",
    "#     model = model.to(device)\n",
    "    \n",
    "    \n",
    "#     threshold_massive = np.linspace (0, n_dots-1, n_dots, dtype=int)\n",
    "#     TP_massive = np.zeros (n_dots)\n",
    "#     FP_massive = np.zeros (n_dots)\n",
    "#     FN_massive = np.zeros (n_dots)\n",
    "#     TN_massive = np.zeros (n_dots)\n",
    "    \n",
    "#     for data in dataLoader:\n",
    "#         inputs = data[0].to(device)\n",
    "#         labels = data[1].to(device)\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         for threshold in threshold_massive:\n",
    "#             prediction = (outputs[:, 1, :, :].unsqueeze(1))>(threshold/n_dots)\n",
    "#             TP_massive[threshold] += torch.sum (prediction       * labels      ).float()\n",
    "#             FP_massive[threshold] += torch.sum (prediction       * (1 - labels)).float()\n",
    "#             FN_massive[threshold] += torch.sum ((1 - prediction) * labels      ).float()\n",
    "#             TN_massive[threshold] += torch.sum ((1 - prediction) * (1 - labels)).float()\n",
    "            \n",
    "#     threshold_massive = threshold_massive / (n_dots-1)\n",
    "#     precision_massive = TP_massive / (TP_massive + FP_massive)\n",
    "#     TPR_massive       = TP_massive / (TP_massive + FN_massive)\n",
    "#     FPR_massive       = FP_massive / (FP_massive + TN_massive)\n",
    "\n",
    "#     sum_events = TP_massive[int(len(TP_massive)/2)] + FP_massive[int(len(FP_massive)/2)] + FN_massive[int(len(FN_massive)/2)] + TN_massive[int(len(TN_massive)/2)] \n",
    "#     print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%')\n",
    "#     print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         print ('TP = ', round(TP_massive[int(len(TP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FP = ', round(FP_massive[int(len(FP_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('FN = ', round(FN_massive[int(len(FN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "#         print ('TN = ', round(TN_massive[int(len(TN_massive)/2)] / sum_events, 6), '%', file=INFO_FILE)\n",
    "    \n",
    "#     # plot 1 precision\n",
    "#     fig1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig1.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, precision_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('precision')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 2 recall\n",
    "#     fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(threshold_massive, TPR_massive, color='green', marker='^')\n",
    "\n",
    "#     axes.set_xlabel('threshold')\n",
    "#     axes.set_ylabel('recall')\n",
    "    \n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # plot 3 ROC-curve\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "#     axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "#     axes.plot(FPR_massive, TPR_massive, 'orange', marker = '^')\n",
    "#     axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "#     axes.set_xlabel('FPR')\n",
    "#     axes.set_ylabel('TPR (recall)')\n",
    "#     axes.set_title('ROC-curve')\n",
    "\n",
    "#     if (SAVE_INFO == True):\n",
    "#         plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "#     plt.show()\n",
    "    \n",
    "#     del model\n",
    "#     del inputs\n",
    "#     del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNetwork_MSE (nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(ConvNetwork_CE, self).__init__()\n",
    "        \n",
    "#         self.features = nn.Sequential()\n",
    "        \n",
    "#         self.features.add_module('conv1', conv_block(     OBSERVED_DAYS    , int (OBSERVED_DAYS/2 ), 3))\n",
    "#         self.features.add_module('conv2', conv_block(int (OBSERVED_DAYS/2 ), int (OBSERVED_DAYS/4 ), 3))\n",
    "#         self.features.add_module('conv3', conv_block(int (OBSERVED_DAYS/4 ), int (OBSERVED_DAYS/8 ), 3))\n",
    "#         self.features.add_module('conv4', conv_block(int (OBSERVED_DAYS/8 ), int (OBSERVED_DAYS/16), 3))\n",
    "#         self.features.add_module('conv5', conv_block(int (OBSERVED_DAYS/16),                      1, 3))\n",
    "        \n",
    "#         # might be a good idea to add an extra full connected layer\n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         print ('input  : ', x.shape)\n",
    "#         x = self.features(x)\n",
    "# #         print ('output : ', x.shape)\n",
    "#         return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_network_MSE(network, \n",
    "#                       device,\n",
    "#                       dataloader_train,\n",
    "#                       dataloader_test,\n",
    "#                       epochs=164,\n",
    "#                       learning_rate=0.1):\n",
    "    \n",
    "#     train_acc = []\n",
    "#     test_acc  = []\n",
    "#     net = network.to(device)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    \n",
    "#     for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#         if epoch == epochs/2:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/10, weight_decay=0.0001, momentum=0.9) \n",
    "#         elif epoch == epochs*3/4:\n",
    "#             optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate/100, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "#         net = net.train()        \n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_train:\n",
    "            \n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)\n",
    "# #             print ('inputs_shape = ', inputs.shape)\n",
    "# #             print ('labels_shape = ', labels.shape)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # forward + backward + optimize\n",
    "#             outputs = net(inputs)\n",
    "# #             print ('outputs : ', outputs.dtype)\n",
    "# #             print ('labels  : ', labels.dtype)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "# #             print (loss)\n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         # calculating test accuracy\n",
    "#         epoch_accuracy = 0.0\n",
    "#         epoch_elems = 0\n",
    "#         for data in dataloader_test:\n",
    "#             inputs = data[0].to(device)\n",
    "#             labels = data[1].to(device)   \n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             epoch_elems    += labels.shape[0]\n",
    "#             epoch_accuracy += loss.item()*labels.shape[0]\n",
    "\n",
    "#         epoch_accuracy /= epoch_elems\n",
    "#         test_acc.append(epoch_accuracy)\n",
    "        \n",
    "        \n",
    "#         print('Epoch : ', epoch, 'acc_train : ', round (train_acc[-1], 4), 'acc_test : ', round (test_acc[-1], 4))\n",
    "\n",
    "#     print('Finished Training')\n",
    "    \n",
    "#     plt.plot(train_acc, label='Train')\n",
    "#     plt.plot(test_acc , label='Test' )\n",
    "#     plt.legend()\n",
    "#     plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthquake_netowrk = ConvNetwork_MSE ()\n",
    "# train_network_MSE (earthquake_netowrk,\n",
    "#                    torch.device(DEVICE),\n",
    "#                    earthquakes_dataloader_train,\n",
    "#                    earthquakes_dataloader_test,\n",
    "#                    epochs=200,\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_mistake (x):\n",
    "#     assert (torch.sum((x < 0.0) + (x > 1.0)) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# print ('input  : ', input.shape, input.dtype)\n",
    "# print (input)\n",
    "# print (torch.sum (input, dim = 0))\n",
    "# print ('target : ', target.shape, target.dtype)\n",
    "# print (target)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class someDataset (Dataset):\n",
    "#     def __init__(self):\n",
    "#         self.data = torch.ones ([100, 32, 10, 10])\n",
    "#         self.labels = torch.ones ([100, 1, 10, 10])\n",
    "#         self.len  = self.data.shape[0]\n",
    "        \n",
    "#         print (self.data.shape)\n",
    "#         print (self.labels.shape)\n",
    "        \n",
    "#     def __len__ (self):\n",
    "#         return self.len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         print ('data_shape = ', self.data[idx].shape)\n",
    "#         print ('result_shape = ', self.labels[idx].shape)\n",
    "#         return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_dataset = someDataset()\n",
    "# dataloader = DataLoader (some_dataset,\n",
    "#                          batch_size=32,\n",
    "#                          shuffle=True,\n",
    "#                          num_workers=1,\n",
    "#                          )\n",
    "\n",
    "# for i, batch in enumerate(dataloader, 0):\n",
    "#     data = batch[0]\n",
    "#     print (i, 'data ', data.shape)\n",
    "#     labels = batch[1]\n",
    "#     print (i, 'labels ', labels.shape)\n",
    "    \n",
    "\n",
    "\n",
    "# # eartquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "# #                                          batch_size=33,\n",
    "# #                                          shuffle=True,\n",
    "# #                                          num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
