{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import datetime as dt\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INFO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SAVE_INFO == True):\n",
    "    DATA_DIR = 'Experiments/'\n",
    "    EXPERIMENT_DIR = DATA_DIR + 'Self_attention+PE(sum)_0/'\n",
    "    os.makedirs(EXPERIMENT_DIR)\n",
    "    \n",
    "READY_DIR = 'ready/with_PE/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посмотрим что мы имеем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение датасета по дням и по клеткам в сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_BORDER = 0\n",
    "RIGHT_BORDER = 2000\n",
    "DOWN_BORDER = 0\n",
    "UP_BORDER = 2500\n",
    "\n",
    "N_CELLS_HOR = 160\n",
    "N_CELLS_VER = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9591, 1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "celled_data = torch.load(\"Data/celled_data_\"\n",
    "                         + str(N_CELLS_HOR)\n",
    "                         + \"x\"\n",
    "                         + str(N_CELLS_VER))\n",
    "print (celled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celled_data_RTL = torch.load(\"Data/RTL_features\")\n",
    "# print (celled_data_RTL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_day_image (tensor, day):\n",
    "    plt.imshow (tensor[day].squeeze(0), cmap=plt.cm.afmhot_r)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_one_day_quakes (tensor, day):\n",
    "    state = tensor[day].squeeze(0)\n",
    "    print (state.shape)\n",
    "    X = []\n",
    "    Y = []\n",
    "    M = []\n",
    "    for i in range(state.shape[0]):\n",
    "        for j in range(state.shape[1]):\n",
    "            if (state[i][j] != 0):\n",
    "                X.append(i)\n",
    "                Y.append(j)\n",
    "                M.append(state[i][j].item())\n",
    "    print (X)\n",
    "    print (Y)\n",
    "    print (M)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "    plt.axis([0, state.shape[0], 0, state.shape[1]])\n",
    "    axes.scatter(X, Y, s=500, c=M, marker='.', cmap=plt.cm.Reds)\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 200])\n",
      "[59, 70, 111, 119]\n",
      "[71, 69, 135, 142]\n",
      "[2.5, 2.5999999046325684, 3.700000047683716, 2.9000000953674316]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_one_day_quakes (celled_data, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:6\n"
     ]
    }
   ],
   "source": [
    "DEVICE_ID = 6\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "# DEVICE = torch.device('cpu')\n",
    "print (DEVICE)\n",
    "# torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def my_accuracy (input, target, threshold):\n",
    "    true = ((input>threshold) == target)\n",
    "    sum = torch.sum (true.float())\n",
    "    return sum/input.shape[0]/input.shape[1]/input.shape[2]/input.shape[3]\n",
    "\n",
    "def my_precision (input, target, threshold):\n",
    "    TP = torch.sum (((input>threshold) * target      ).float())\n",
    "    FP = torch.sum (((input>threshold) * (1 - target)).float())\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def my_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target).float())\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def my_precision_recall (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold)  * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold)  * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)) * target      ).float())\n",
    "#     print ('TP = ', TP.item(), 'FP = ', FP.item(), 'FN = ', FN.item(), 'N = ', input.shape[0])\n",
    "    return TP / (TP + FP), TP / (TP + FN)\n",
    "\n",
    "def my_precision_TPR_FPR (input, target, threshold):\n",
    "    TP = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    FP = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    FN = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    TN = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return TP / (TP + FP), TP / (TP + FN), FP / (FP + TN)\n",
    "\n",
    "def my_TP_FN_FP_TN (input, target, threshold):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    matrix[0, 0] = torch.sum ((     (input>threshold) .float() * target      ).float())\n",
    "    matrix[1, 0] = torch.sum ((     (input>threshold) .float() * (1 - target)).float())\n",
    "    matrix[0, 1] = torch.sum (((1 - (input>threshold)).float() * target      ).float())\n",
    "    matrix[1, 1] = torch.sum (((1 - (input>threshold)).float() * (1 - target)).float())\n",
    "    return matrix / np.sum(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет\n",
    "#### (Может не влезть в оперативку (надо ~ 12Gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVED_DAYS = 64     # ~2 months\n",
    "DAYS_TO_PREDICT_AFTER  = 10\n",
    "DAYS_TO_PREDICT_BEFORE = 50\n",
    "TESTING_DAYS = 1000\n",
    "\n",
    "HEAVY_QUAKE_THRES = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = (celled_data>HEAVY_QUAKE_THRES).float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 160, 200])\n"
     ]
    }
   ],
   "source": [
    "print (mean_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeDataset_RNN_Usual_Train (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[0:\n",
    "                                (celled_data.shape[0] -\n",
    "                                 TESTING_DAYS)]\n",
    "        \n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        accurate_pred = ((torch.sum(self.data[(idx +\n",
    "                                              DAYS_TO_PREDICT_AFTER):\n",
    "                                             (idx +\n",
    "                                              DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                                   dim=0,\n",
    "                                   keepdim=True).squeeze(0) > 0).float()\n",
    "                         - mean_val)\n",
    "        return (self.data[(idx)],\n",
    "                torch.cat([1 - accurate_pred, accurate_pred], dim=0))\n",
    "        \n",
    "\n",
    "class EarthquakeDataset_RNN_Usual_Test (Dataset):\n",
    "    def __init__(self, celled_data):\n",
    "        self.data = celled_data[(celled_data.shape[0] -\n",
    "                                 TESTING_DAYS):\n",
    "                                (celled_data.shape[0])]\n",
    "        self.size = (self.data.shape[0] -\n",
    "                     DAYS_TO_PREDICT_BEFORE)\n",
    "    \n",
    "        print ('self.data :', self.data.shape)\n",
    "        print ('size      :', self.size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[(idx)],\n",
    "                torch.sum(self.data[(idx +\n",
    "                                     DAYS_TO_PREDICT_AFTER):\n",
    "                                    (idx +\n",
    "                                     DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "                          dim=0,\n",
    "                          keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EarthquakeDataset_RNN_Train (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[0:\n",
    "#                                 (celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS)]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[idx],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)\n",
    "        \n",
    "\n",
    "# class EarthquakeDataset_RNN_Test (Dataset):\n",
    "#     def __init__(self, celled_data):\n",
    "#         self.data = celled_data[(celled_data.shape[0] -\n",
    "#                                  TESTING_DAYS):\n",
    "#                                 (celled_data.shape[0])]\n",
    "#         self.size = (self.data.shape[0] -\n",
    "#                      DAYS_TO_PREDICT_BEFORE)\n",
    "        \n",
    "#         print ('self.data :', self.data.shape)\n",
    "#         print ('size      :', self.size)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.size\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return (self.data[(idx)],\n",
    "#                 torch.sum(self.data[(idx +\n",
    "#                                      DAYS_TO_PREDICT_AFTER):\n",
    "#                                     (idx +\n",
    "#                                      DAYS_TO_PREDICT_BEFORE)] > HEAVY_QUAKE_THRES,\n",
    "#                           dim=0,\n",
    "#                           keepdim=True).squeeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data : torch.Size([8591, 1, 160, 200])\n",
      "size      : 8541\n",
      "self.data : torch.Size([1000, 1, 160, 200])\n",
      "size      : 950\n"
     ]
    }
   ],
   "source": [
    "earthquakes_dataset_train = EarthquakeDataset_RNN_Usual_Train (celled_data)\n",
    "earthquakes_dataset_test  = EarthquakeDataset_RNN_Usual_Test  (celled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes_dataloader_train = DataLoader(earthquakes_dataset_train,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "\n",
    "earthquakes_dataloader_test  = DataLoader(earthquakes_dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим саму сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.CONV  = nn.Conv2d    (in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   bias=False)             # think about it later\n",
    "        \n",
    "        self.BNORM =nn.BatchNorm2d(out_channels,\n",
    "                                   eps=1e-05,\n",
    "                                   momentum=0.1,\n",
    "                                   affine=False)\n",
    "#         self.RELU  = nn.ReLU ()\n",
    "        \n",
    "#         self.MAXPOOL = nn.MaxPool2d(3,\n",
    "#                                     stride=1,\n",
    "#                                     padding=1,\n",
    "#                                     dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print ('sizeof(x) = ', x.size())\n",
    "        #print ('sizeof(xprev) = ', xprev.size())    \n",
    "        \n",
    "        x = self.CONV   (x)\n",
    "        x = self.BNORM  (x)\n",
    "#         x = self.RELU   (x)\n",
    "#         x = self.MAXPOOL(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySoftMax (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        x = x.exp()\n",
    "        return x / x.sum(dim=(1, 2), keepdim=True)\n",
    "        \n",
    "\n",
    "class SelfAttention (nn.Module):\n",
    "    \n",
    "    def __init__ (self, emb_size, query_key_size, value_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_size       = emb_size\n",
    "        self.query_key_size = query_key_size\n",
    "        self.value_size     = value_size\n",
    "        \n",
    "        self.emb_to_query = nn.Linear(emb_size, query_key_size)\n",
    "        self.emb_to_key   = nn.Linear(emb_size, query_key_size)\n",
    "        self.emb_to_value = nn.Linear(emb_size, value_size)\n",
    "        \n",
    "        self.softmax = MySoftMax()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        \n",
    "        emb = x.permute((0, 2, 3, 1))\n",
    "        \n",
    "#         print (emb.shape)\n",
    "        \n",
    "        queries = self.emb_to_query(emb)\n",
    "        keys    = self.emb_to_key  (emb)\n",
    "        values  = self.emb_to_value(emb)\n",
    "        \n",
    "        ret = torch.empty_like(values)\n",
    "        \n",
    "        for i in range(queries.shape[1]):\n",
    "            for j in range(queries.shape[2]):\n",
    "                \n",
    "                weights = torch.sum(keys * queries[:, i, j, :].unsqueeze(1).unsqueeze(1),\n",
    "                                    dim=3)\n",
    "                weights /= self.query_key_size\n",
    "                weights = self.softmax(weights)\n",
    "                \n",
    "                weighted_values = values * weights.unsqueeze(3)\n",
    "                \n",
    "                ret[:, i, j, :] = weighted_values.sum(dim=(1, 2))\n",
    "        \n",
    "        return ret.permute((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding (nn.Module):\n",
    "    def __init__(self, n_mod, denom):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_mod = n_mod\n",
    "        self.denom = denom\n",
    "        \n",
    "        self.carriers = 1 / torch.pow(denom, (torch.arange(n_mod, dtype=torch.float, device=DEVICE) + 1) / n_mod)\n",
    "        \n",
    "    def make_PE_matrix (self, hor_len, ver_len):\n",
    "        \n",
    "        matrix = torch.ones([self.n_mod, hor_len, ver_len], dtype=torch.float, device=DEVICE)\n",
    "        matrix = matrix * self.carriers.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        hor_positions = torch.arange(hor_len, dtype=torch.float, device=DEVICE).unsqueeze(1)\n",
    "        ver_positions = torch.arange(ver_len, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
    "        \n",
    "        matrix_hor = matrix * hor_positions.unsqueeze(0)\n",
    "        matrix_ver = matrix * ver_positions.unsqueeze(0)\n",
    "        \n",
    "        for i in range(self.n_mod):\n",
    "            if   i%2 == 0:\n",
    "                matrix[i, :, :] = (torch.sin(matrix_hor[i, :, :]) * \n",
    "                                   torch.sin(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 1:\n",
    "                matrix[i, :, :] = (torch.sin(matrix_hor[i, :, :]) * \n",
    "                                   torch.cos(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 2:\n",
    "                matrix[i, :, :] = (torch.cos(matrix_hor[i, :, :]) * \n",
    "                                   torch.sin(matrix_ver[i, :, :]))\n",
    "            elif i%2 == 3:\n",
    "                matrix[i, :, :] = (torch.cos(matrix_hor[i, :, :]) * \n",
    "                                   torch.cos(matrix_ver[i, :, :]))    \n",
    "        return matrix\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.ones((2, 5, 5))\n",
    "\n",
    "# # softmax = nn.Softmax2d()\n",
    "\n",
    "# # a = softmax(a)\n",
    "\n",
    "# a = a.unsqueeze(-1)\n",
    "\n",
    "# print (a.shape)\n",
    "# print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell (nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size=16, hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.  h_size = hidden_state_size\n",
    "        \n",
    "        self.embedding  = ConvBlock (1, embedding_size, 3)\n",
    "        self.RNN_update = nn.Sequential (ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size + embedding_size,\n",
    "                                                    kernel_size=3),\n",
    "                                         ConvBlock (hidden_state_size + embedding_size,\n",
    "                                                    hidden_state_size,\n",
    "                                                    kernel_size=3))\n",
    "        self.RNN_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                       2, \n",
    "                                                       kernel_size=3),\n",
    "                                            nn.Softmax (dim=1))\n",
    "        \n",
    "    def forward (self, x, h_prev):\n",
    "        \n",
    "        x_emb   = self.embedding (x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
    "#         print (\"x_and_h : \", x_and_h.shape)\n",
    "        h_next  = self.RNN_update(x_and_h)\n",
    "#         print (\"h_prev :\", h_prev.shape)\n",
    "#         print (\"h_next :\", h_next.shape)\n",
    "        \n",
    "        assert h_prev.shape == h_next.shape\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        result = self.RNN_to_result(h_next)\n",
    "        return h_next, result\n",
    "    \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return torch.zeros(batch_size,\n",
    "                           self.h_size,\n",
    "                           N_CELLS_HOR, \n",
    "                           N_CELLS_VER,\n",
    "                           requires_grad=False,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "![LSTM](./img/LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell (nn.Module):\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  embedding_size=16,\n",
    "                  hidden_state_size=32):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.emb_size = embedding_size\n",
    "        self.hid_size = hidden_state_size\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(embedding_size, 250 / m.pi / 2)\n",
    "        \n",
    "        self.PE_matrix = self.pos_encoding.make_PE_matrix(N_CELLS_HOR, N_CELLS_VER)\n",
    "        \n",
    "        self.self_attention = SelfAttention(emb_size=embedding_size,\n",
    "                                            query_key_size=embedding_size,\n",
    "                                            value_size=embedding_size)\n",
    "                \n",
    "#         self.embedding = ConvBlock (1, self.emb_size, kernel_size=3)\n",
    "        self.embedding = nn.Sequential(ConvBlock(1,\n",
    "                                                 self.emb_size,\n",
    "                                                 3),\n",
    "                                       nn.ReLU(),\n",
    "                                       ConvBlock(self.emb_size,\n",
    "                                                 self.emb_size,\n",
    "                                                 3))\n",
    "    \n",
    "        self.hidden_to_result = nn.Sequential (ConvBlock (hidden_state_size, \n",
    "                                                          2, \n",
    "                                                          kernel_size=3),\n",
    "                                               nn.Softmax (dim=1))\n",
    "        \n",
    "        self.f_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.i_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        self.c_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Tanh())\n",
    "        self.o_t = nn.Sequential (ConvBlock(self.hid_size + self.emb_size,\n",
    "                                            self.hid_size,\n",
    "                                            3),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward (self, x, prev_state):\n",
    "        \n",
    "        (prev_c, prev_h) = prev_state\n",
    "        x_emb = self.embedding(x)\n",
    "#         print (x_emb.shape)\n",
    "        x_emb = x_emb + self.self_attention(x_emb + self.PE_matrix)\n",
    "        \n",
    "        x_and_h = torch.cat([prev_h, x_emb], dim=1)\n",
    "        \n",
    "        f_i = self.f_t(x_and_h)\n",
    "        i_i = self.i_t(x_and_h)\n",
    "        c_i = self.c_t(x_and_h)\n",
    "        o_i = self.o_t(x_and_h)\n",
    "        \n",
    "        next_c = prev_c * f_i + i_i * c_i\n",
    "        next_h = torch.tanh(next_c) * o_i\n",
    "        \n",
    "        assert prev_h.shape == next_h.shape\n",
    "        assert prev_c.shape == next_c.shape\n",
    "        \n",
    "        return (next_c, next_h), self.hidden_to_result(next_h)\n",
    "        \n",
    "    def init_state (self, batch_size, device=torch.device(\"cpu\")):\n",
    "        return (Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)),\n",
    "                Variable(torch.zeros(batch_size,\n",
    "                                     self.hid_size,\n",
    "                                     N_CELLS_HOR,\n",
    "                                     N_CELLS_VER,\n",
    "                                     device=device)))\n",
    "               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция тренеровки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossEntropy(weights, prediction, target):\n",
    "    assert len(weights) == prediction.shape[1]\n",
    "    assert prediction.shape == target.shape\n",
    "    loss = 0\n",
    "    \n",
    "#     print (prediction.shape)\n",
    "#     print ((prediction>0).sum().item())\n",
    "#     print ((prediction<0).sum().item())\n",
    "#     print ((prediction==0).sum().item())\n",
    "    \n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(len(weights)):\n",
    "            loss -= weights[j] * torch.sum(target[i, j] * prediction[i, j].log())\n",
    "    return loss / prediction.shape[2] / prediction.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_RNN (RNN_cell,\n",
    "                       device,\n",
    "                       dataloader_train,\n",
    "                       n_cycles=1,\n",
    "                       learning_rate=0.0003,\n",
    "                       earthquake_weight=1.,\n",
    "                       lr_decay=1.):\n",
    "    \n",
    "    loss_massive = []\n",
    "    i = 0\n",
    "    \n",
    "    RNN_cell.to(device)\n",
    "    \n",
    "    weights = torch.tensor([1., earthquake_weight], dtype=torch.float).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weights)\n",
    "    \n",
    "    i = 0\n",
    "    for cycle in range(n_cycles):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(RNN_cell.parameters(), lr=learning_rate)\n",
    "#         optimizer = torch.optim.SGD(RNN_cell.parameters(), lr=learning_rate)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "#         for data in tqdm(dataloader_train):\n",
    "        for data in dataloader_train:\n",
    "            \n",
    "#             print (\"step No \", i)\n",
    "            \n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            \n",
    "#             print (\"inputs\", inputs.shape)\n",
    "#             print (\"hid_state\", hid_state.shape)\n",
    "            hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "            \n",
    "#             loss = criterion(outputs, labels.squeeze(1).long())\n",
    "            loss = my_crossEntropy(weights, outputs, labels)\n",
    "#             print (\"Loss : \", loss.item())\n",
    "            if (m.isnan(loss.item())):\n",
    "                print (\"We have NaN !!!!!!!!!!\")\n",
    "                break\n",
    "            loss_massive.append(loss.item())\n",
    "#             loss.backward(retain_graph=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             print (\"day : \", i, \"loss : \", loss.item())\n",
    "            \n",
    "            if (type(hid_state) == tuple):\n",
    "                for elem in hid_state:\n",
    "                    elem.detach_()\n",
    "            else:\n",
    "                hid_state.detach_()\n",
    "            \n",
    "            if (i)%100==0:\n",
    "                clear_output(True)\n",
    "                print (\"Done :\", i, \"/\", dataloader_train.__len__())\n",
    "                plt.plot(loss_massive,label='loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "            os.mkdir(READY_DIR + str(i))\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "        learning_rate /= lr_decay\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CYCLES = 1\n",
    "LEARNING_RATE = 0.0003\n",
    "LR_DECAY = 10.\n",
    "EARTHQUAKE_WEIGHT = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 16\n",
    "HID_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN_cell = RNNCell()\n",
    "RNN_cell = LSTMCell(embedding_size    = EMB_SIZE,\n",
    "                    hidden_state_size = HID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done : 0 / 8541\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPcElEQVR4nO3dbYxc5XmH8euO7bIKtgPYa0OyIQtqpQImELqYVlQL5AUCSXiJ+wHUQKCARYto+gIJiCjlpRUNtAJFJbUsBIVGDqYNltLQGigBGVTSsjY2mBDAMdCsTeu1CaQUmYJ998OebZdl1juzM7Pjfbh+0mjOnOeec+7HK/199pwzs5GZSJKmvw90ugFJUmsY6JJUCANdkgphoEtSIQx0SSrEzE7teP78+dnb29up3UvStLR27drtmdlda6xjgd7b28vAwECndi9J01JEvDzemKdcJKkQBrokFcJAl6RCdOwcuiS1wttvv83g4CA7d+7sdCst1dXVRU9PD7Nmzar7PQa6pGltcHCQOXPm0NvbS0R0up2WyEx27NjB4OAghxxySN3v85SLpGlt586dzJs3r5gwB4gI5s2b1/BvHQa6pGmvpDAfMZk5GeiSVAgDXZKaNHv27E63ABjoklQMA12SWiQzueKKK1i0aBFHHnkkK1euBOCVV16hv7+fo48+mkWLFvHoo4+ya9cuzj///P+rvfnmm5vev7ctSirGtf/wDD/e+ouWbvPwD8/lT75wRF219957L+vXr2fDhg1s376dY489lv7+flasWMEpp5zC1Vdfza5du3jzzTdZv349W7ZsYePGjQC89tprTffqEboktchjjz3GOeecw4wZM1i4cCEnnHACTzzxBMceeyx33HEH11xzDU8//TRz5szh0EMPZfPmzVx22WWsXr2auXPnNr1/j9AlFaPeI+l2ycya6/v7+1mzZg333Xcf5557LldccQXnnXceGzZs4P777+fWW2/lnnvu4fbbb29q/x6hS1KL9Pf3s3LlSnbt2sXQ0BBr1qxh8eLFvPzyyyxYsICLL76YCy+8kHXr1rF9+3Z2797NkiVLuP7661m3bl3T+/cIXZJa5KyzzuLxxx/nqKOOIiK48cYbOfDAA7nzzju56aabmDVrFrNnz+auu+5iy5YtXHDBBezevRuAG264oen9x3i/IrRbX19f+gcuJDXr2Wef5bDDDut0G21Ra24RsTYz+2rVe8pFkgphoEtSIQx0SdNep04dt9Nk5mSgS5rWurq62LFjR1GhPvJ96F1dXQ29z7tcJE1rPT09DA4OMjQ01OlWWmrkLxY1wkCXNK3NmjWrob/qUzJPuUhSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqRF0f/Y+Il4D/AnYB74z9cvWI+G3ga9XLN4DfzcwNLexTkjSBRr7L5aTM3D7O2IvACZn584g4FVgOHNd0d5KkurXky7ky819GvfwR0NhXhEmSmlbvOfQEHoiItRGxdILaC4F/qjUQEUsjYiAiBkr7qktJ6rR6j9CPz8ytEbEAeDAifpKZa8YWRcRJDAf6b9baSGYuZ/h0DH19feV8G70k7QXqOkLPzK3V8zZgFbB4bE1EfBy4DTgjM3e0sklJ0sQmDPSI2Dci5owsAycDG8fUHAzcC5ybmc+3o1FJ0p7Vc8plIbAqIkbqV2Tm6oi4BCAzlwHfAOYB367q3nNroySpvSYM9MzcDBxVY/2yUcsXARe1tjVJUiP8pKgkFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqRF2BHhEvRcTTEbE+IgZqjP9qRDweEW9FxOWtb1OSNJGZDdSelJnbxxl7Ffh94MzmW5IkTUZLTrlk5rbMfAJ4uxXbkyQ1rt5AT+CBiFgbEUsnu7OIWBoRAxExMDQ0NNnNSJJqqDfQj8/MY4BTgUsjon8yO8vM5ZnZl5l93d3dk9mEJGkcdQV6Zm6tnrcBq4DF7WxKktS4CQM9IvaNiDkjy8DJwMZ2NyZJakw9d7ksBFZFxEj9isxcHRGXAGTmsog4EBgA5gK7I+IPgMMz8xdt6luSNMaEgZ6Zm4GjaqxfNmr5P4Ce1rYmSWqEnxSVpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5Jhagr0CPipYh4OiLWR8RAjfGIiG9FxKaIeCoijml9q5KkPZnZQO1Jmbl9nLFTgV+pHscBf109S5KmSKtOuZwB3JXDfgTsFxEHtWjbkqQ61BvoCTwQEWsjYmmN8Y8APxv1erBa9y4RsTQiBiJiYGhoqPFuJUnjqjfQj8/MYxg+tXJpRPSPGY8a78n3rMhcnpl9mdnX3d3dYKuSpD2pK9Azc2v1vA1YBSweUzIIfHTU6x5gaysalCTVZ8JAj4h9I2LOyDJwMrBxTNn3gfOqu11+HXg9M19pebeSpHHVc5fLQmBVRIzUr8jM1RFxCUBmLgP+ETgN2AS8CVzQnnYlSeOZMNAzczNwVI31y0YtJ3Bpa1uTJDXCT4pKUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklSIugM9ImZExJMR8YMaYx+LiIci4qmIeCQielrbpiRpIo0coX8FeHacsb8A7srMjwPXATc025gkqTF1BXp1xP054LZxSg4HHqqWHwbOaL41SVIj6j1CvwX4KrB7nPENwJJq+SxgTkTMG1sUEUsjYiAiBoaGhhpuVpI0vgkDPSI+D2zLzLV7KLscOCEingROALYA74wtyszlmdmXmX3d3d2T7VmSVMPMOmqOB06PiNOALmBuRHwnM780UpCZW4EvAkTEbGBJZr7ejoYlSbVNeISemVdlZk9m9gJnAz8cHeYAETE/Ika2dRVwe8s7lSTt0aTvQ4+I6yLi9OrlicBzEfE8sBD4sxb0JklqQGRmR3bc19eXAwMDHdm3JE1XEbE2M/tqjflJUUkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklSIugM9ImZExJMR8YMaYwdHxMPV+FMRcVpr25QkTaSRI/SvAM+OM/Z14J7M/ARwNvDtZhuTJDWmrkCPiB7gc8Bt45QkMLda/hCwtfnWJEmNmFln3S3AV4E544xfAzwQEZcB+wKfrlUUEUuBpQAHH3xwQ41KkvZswiP0iPg8sC0z1+6h7BzgbzKzBzgN+NuIeM+2M3N5ZvZlZl93d/ekm5YkvVc9p1yOB06PiJeAu4FPRsR3xtRcCNwDkJmPA13A/Bb2KUmawISBnplXZWZPZvYyfMHzh5n5pTFl/w58CiAiDmM40Ida3KskaQ8mfR96RFwXEadXL/8YuDgiNgDfBc7PzGxFg5Kk+tR7URSAzHwEeKRa/sao9T9m+NSMJKlD/KSoJBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFSI69ZfiImIIeLkjO2/OfGB7p5uYYs65fO+3+cL0nfPHMrO71kDHAn26ioiBzOzrdB9TyTmX7/02Xyhzzp5ykaRCGOiSVAgDvXHLO91ABzjn8r3f5gsFztlz6JJUCI/QJakQBrokFcJAryEiDoiIByPihep5/3HqvlzVvBARX64x/v2I2Nj+jpvXzJwj4oMRcV9E/CQinomIP5/a7usXEZ+NiOciYlNEXFljfJ+IWFmN/2tE9I4au6pa/1xEnDKVfTdjsnOOiM9ExNqIeLp6/uRU9z5Zzfycq/GDI+KNiLh8qnpuicz0MeYB3AhcWS1fCXyzRs0BwObqef9qef9R418EVgAbOz2fds8Z+CBwUlXzS8CjwKmdnlON/mcAPwUOrfrcABw+pub3gGXV8tnAymr58Kp+H+CQajszOj2nNs/5E8CHq+VFwJZOz6fdcx41/j3g74DLOz2fRh4eodd2BnBntXwncGaNmlOABzPz1cz8OfAg8FmAiJgN/BHwp1PQa6tMes6Z+WZmPgyQmf8DrAN6pqDnRi0GNmXm5qrPuxme92ij/x3+HvhURES1/u7MfCszXwQ2Vdvb2016zpn5ZGZurdY/A3RFxD5T0nVzmvk5ExFnMnyw8swU9dsyBnptCzPzFYDqeUGNmo8APxv1erBaB3A98JfAm+1sssWanTMAEbEf8AXgoTb12YwJ+x9dk5nvAK8D8+p8796omTmPtgR4MjPfalOfrTTpOUfEvsDXgGunoM+Wm9npBjolIv4ZOLDG0NX1bqLGuoyIo4Ffzsw/HHtertPaNedR258JfBf4VmZubrzDtttj/xPU1PPevVEzcx4ejDgC+CZwcgv7aqdm5nwtcHNmvlEdsE8r79tAz8xPjzcWEf8ZEQdl5isRcRCwrUbZIHDiqNc9wCPAbwC/FhEvMfzvuyAiHsnME+mwNs55xHLghcy8pQXttsMg8NFRr3uArePUDFb/QX0IeLXO9+6NmpkzEdEDrALOy8yftr/dlmhmzscBvxURNwL7AbsjYmdm/lX7226BTp/E3xsfwE28+wLhjTVqDgBeZPii4P7V8gFjanqZPhdFm5ozw9cLvgd8oNNz2cMcZzJ8bvQQ/v9i2RFjai7l3RfL7qmWj+DdF0U3Mz0uijYz5/2q+iWdnsdUzXlMzTVMs4uiHW9gb3wwfP7wIeCF6nkktPqA20bV/Q7DF8c2ARfU2M50CvRJz5nhI6AEngXWV4+LOj2nceZ5GvA8w3dBXF2tuw44vVruYvjuhk3AvwGHjnrv1dX7nmMvvIun1XMGvg7896if6XpgQafn0+6f86htTLtA96P/klQI73KRpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQ/wsD/sl3/DBHyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN_cell.apply(init_weights)\n",
    "train_network_RNN (RNN_cell,\n",
    "                   DEVICE,\n",
    "                   earthquakes_dataloader_train,\n",
    "                   n_cycles=N_CYCLES,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   earthquake_weight=EARTHQUAKE_WEIGHT,\n",
    "                   lr_decay=LR_DECAY\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(READY_DIR + 'Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality (RNN_cell,\n",
    "                   device,\n",
    "                   dataloader_test,\n",
    "                   n_dots=501,\n",
    "                   info_file=None):\n",
    "    \n",
    "    prediction = torch.zeros(dataloader_test.__len__(),  N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    prediction.detach_()\n",
    "    target     = torch.zeros(dataloader_test.__len__(), N_CELLS_HOR, N_CELLS_VER,\n",
    "                             device=device,\n",
    "                             dtype=torch.float)\n",
    "    target.detach_()\n",
    "       \n",
    "    RNN_cell.to(device)\n",
    "\n",
    "    hid_state = RNN_cell.init_state(batch_size=1, device=device)\n",
    "    if (type(hid_state) == tuple):\n",
    "        for elem in hid_state:\n",
    "            elem.detach_()\n",
    "    else:\n",
    "        hid_state.detach_()\n",
    "        \n",
    "    i = 0\n",
    "    for data in tqdm(dataloader_test):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device).float()\n",
    "\n",
    "        hid_state, outputs = RNN_cell.forward(inputs, hid_state)\n",
    "        \n",
    "        prediction[i] = outputs[:, 1, :, :]\n",
    "        target    [i] = labels.squeeze(0)\n",
    "    \n",
    "        if (type(hid_state) == tuple):\n",
    "            for elem in hid_state:\n",
    "                elem.detach_()\n",
    "        else:\n",
    "            hid_state.detach_()\n",
    "        prediction.detach_()\n",
    "        target    .detach_()\n",
    "        i += 1\n",
    "        \n",
    "    assert prediction.shape == target.shape\n",
    "    prediction = prediction [10:prediction.shape[0]]  # cutting peace of data because\n",
    "    prediction += mean_val.to(device)\n",
    "    target     = target     [10:target    .shape[0]]  # hidden state might be not good\n",
    "    \n",
    "    print (\"ROC_AUC_score = \", end='')\n",
    "    ROC_AUC_score = roc_auc_score(np.array(target    .view(-1).cpu()),\n",
    "                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (ROC_AUC_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('ROC_AUC               =', ROC_AUC_score, file=info_file)\n",
    "    \n",
    "    print (\"AVG_precision_score = \", end='')\n",
    "    AVG_precision_score = average_precision_score(np.array(target    .view(-1).cpu()),\n",
    "                                                  np.array(prediction.view(-1).cpu()))\n",
    "    print (AVG_precision_score)\n",
    "    if (SAVE_INFO):\n",
    "        print ('Average_precision     =', AVG_precision_score, file=info_file)\n",
    "        \n",
    "    print ('\\n=======================')\n",
    "    \n",
    "    for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "        print ('Threshold = ', threshold)\n",
    "        print ('-----------------------')\n",
    "        print (my_TP_FN_FP_TN(prediction, target, threshold))\n",
    "        print ('=======================')\n",
    "    \n",
    "    if SAVE_INFO:\n",
    "        print ('\\n=======================', file=info_file)\n",
    "    \n",
    "        for threshold in (0.2, 0.4, 0.6, 0.8):\n",
    "            print ('Threshold = ', threshold                    , file=info_file)\n",
    "            print ('-----------------------'                    , file=info_file)\n",
    "            print (my_TP_FN_FP_TN(prediction, target, threshold), file=info_file)\n",
    "            print ('======================='                    , file=info_file)\n",
    "    \n",
    "    threshold_massive = torch.linspace (0, 1, n_dots, dtype=torch.float, device=device)\n",
    "    \n",
    "#     precision = np.zeros(n_dots)\n",
    "#     recall    = np.zeros(n_dots)\n",
    "#     FPR       = np.zeros(n_dots)\n",
    "\n",
    "    precision_massive = []\n",
    "    recall_massive    = []\n",
    "    FPR_massive       = []\n",
    "    \n",
    "    for threshold in tqdm(threshold_massive):\n",
    "        precision, recall, FPR = my_precision_TPR_FPR(prediction, target, threshold)\n",
    "        precision_massive.append(precision.item())\n",
    "        recall_massive   .append(recall.item())\n",
    "        FPR_massive      .append(FPR.item())\n",
    "    \n",
    "    # plot 1 precision\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), precision_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('precision')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 2 recall\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(np.array(threshold_massive.cpu()), recall_massive, color='green', marker='^')\n",
    "\n",
    "    axes.set_xlabel('threshold')\n",
    "    axes.set_ylabel('recall')\n",
    "    \n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Recall_from_threshold.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 3 ROC-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(FPR_massive, recall_massive, 'orange', marker = '^')\n",
    "    axes.plot (range(2), range(2), 'grey', ls='--')\n",
    "\n",
    "    axes.set_xlabel('FPR')\n",
    "    axes.set_ylabel('TPR (recall)')\n",
    "    axes.set_title('ROC-curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'ROC_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot 4 precision-recall-curve\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "    axes.plot(recall_massive, precision_massive, 'orange', marker = '^')\n",
    "\n",
    "    axes.set_xlabel('Recall')\n",
    "    axes.set_ylabel('Precision')\n",
    "    axes.set_title('Precision_Recall_curve')\n",
    "\n",
    "    if (SAVE_INFO == True):\n",
    "        plt.savefig(EXPERIMENT_DIR + 'Precision_Recall_curve.png', format='png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    return ROC_AUC_score, AVG_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_INFO_to_file(info_file):\n",
    "        \n",
    "    print ('LEFT_BORDER           =', LEFT_BORDER                           , file=info_file)\n",
    "    print ('RIGHT_BORDER          =', RIGHT_BORDER                          , file=info_file)\n",
    "    print ('DOWN_BORDER           =', DOWN_BORDER                           , file=info_file)\n",
    "    print ('UP_BORDER             =', UP_BORDER                             , file=info_file)\n",
    "    print ('N_CELLS_HOR           =', N_CELLS_HOR                           , file=info_file)\n",
    "    print ('N_CELLS_VER           =', N_CELLS_VER                           , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('OBSERVED_DAYS         =', OBSERVED_DAYS                         , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_AFTER =', DAYS_TO_PREDICT_AFTER                 , file=info_file)\n",
    "    print ('DAYS_TO_PREDICT_BEFOR =', DAYS_TO_PREDICT_BEFORE                , file=info_file)\n",
    "    print ('TESTING_DAYS          =', TESTING_DAYS                          , file=info_file)\n",
    "    print ('HEAVY_QUAKE_THRES     =', HEAVY_QUAKE_THRES                     , file=info_file)\n",
    "    print ('LEARNING_RATE         =', LEARNING_RATE                         , file=info_file)\n",
    "    print ('LR_DECAY              =', LR_DECAY                              , file=info_file)\n",
    "    print ('N_CYCLES              =', N_CYCLES                              , file=info_file)\n",
    "    print ('EARTHQUAKE_WEIGHT     =', EARTHQUAKE_WEIGHT                     , file=info_file)\n",
    "    print ('TRAIN_SHAPE           =', earthquakes_dataset_train.data.shape  , file=info_file)\n",
    "    print ('TEST__SHAPE           =', earthquakes_dataset_test .data.shape  , file=info_file)\n",
    "    print (' '                                                              , file=info_file)\n",
    "    print ('EMB_SIZE              =', EMB_SIZE                              , file=info_file)\n",
    "    print ('HID_SIZE              =', HID_SIZE                              , file=info_file)\n",
    "    \n",
    "    \n",
    "#         print ('', , file=info_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    RNN_cell.eval()\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        info_file = open (EXPERIMENT_DIR + 'INFO.txt', 'w')\n",
    "    else:\n",
    "        info_file = None\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        print_INFO_to_file(info_file)\n",
    "\n",
    "    ROC_AUC, AVG_prec = check_quality (RNN_cell,\n",
    "                                       DEVICE,\n",
    "                                       earthquakes_dataloader_test,\n",
    "                                       n_dots=251,\n",
    "                                       info_file=info_file)\n",
    "\n",
    "    if SAVE_INFO:\n",
    "        info_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
